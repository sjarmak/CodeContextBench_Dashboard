name: reference_correctness
version: "1.0"
system_prompt: |
  You are an expert evaluator comparing an agent's output against a reference answer for correctness.

  IMPORTANT ANTI-BIAS INSTRUCTIONS:
  - Do NOT prefer longer responses. Evaluate substance over verbosity.
  - The agent does NOT need to match the reference word-for-word.
  - An agent output that arrives at the correct answer via a different approach is equally valid.
  - Focus on whether the agent's output is factually correct and addresses the task requirements.

  Provide your evaluation as chain-of-thought reasoning followed by a structured JSON verdict.

user_prompt_template: |
  ## Task Description
  {task_description}

  ## Reference Answer (Ground Truth)
  {reference_answer}

  ## Context Files
  {context_files}

  ## Agent Output
  {agent_output}

  ## Instructions
  Compare the agent's output against the reference answer for correctness:
  1. Identify key facts and claims in the reference answer
  2. Check if the agent's output correctly addresses each key point
  3. Note any factual errors or omissions in the agent's output
  4. Consider whether the agent used a valid alternative approach

  Score using a 3-point scale:
  - pass (1.0): Agent output is correct and addresses the task
  - partial (0.5): Agent output is partially correct with some errors or omissions
  - fail (0.0): Agent output is incorrect or does not address the task

  Respond with valid JSON only (escape all quotes and special characters):
  {output_format}

output_format_spec: |
  {
    "reasoning": "Your chain-of-thought analysis...",
    "dimension_scores": {
      "Oracle Correctness": {"score": 1.0, "evidence": "...", "reasoning": "..."},
      "Approach Alignment": {"score": 0.5, "evidence": "...", "reasoning": "..."}
    },
    "context_file_coverage": 0.8,
    "overall_score": 0.75,
    "confidence": 0.85
  }

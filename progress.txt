# Ralph Progress Log
Started: Sat Jan 31 23:09:13 EST 2026
---

## Codebase Patterns
- 10Figure corpus lives at `~/10Figure-Codebases/src/{repo}/` with repos: kubernetes, envoy, django, tensorflow
- Base Docker image built via `base/build.sh`, copies entire corpus (~6-8GB) into container at `/10figure/`
- All tasks follow structure: `instruction.md`, `task.toml`, `task.yaml`, `environment/Dockerfile`, `tests/test.sh`, `tests/expected_changes.json`
- Validation uses `/10figure/scripts/validate_patch.py` inside the container (not in benchmark dir)
- Task Dockerfiles inherit from `harbor-10figure:base`, specified in `task.toml` as `localhost/harbor-10figure:base`
- sg-benchmarks org has `kubernetes--latest` mirror; django has 230 SWE-bench commit mirrors; no envoy/tensorflow mirrors yet
- Existing 4 scored tasks are all Kubernetes-only (api_upgrade_01, bug_localization_01, cross_file_reasoning_01, refactor_rename_01)
- Template `templates/test.sh.j2` generates test.sh scripts; expects patch at `/logs/agent/patch.diff`

## 2026-01-31 - US-007
- Created `benchmarks/10figure/cross_refactor_01/` task package (Envoy + Kubernetes)
- Task: rename gRPC health check service field from `service_name` (Envoy) / `Service` (K8s) to `grpc_service_name` / `GRPCServiceName`
- 8 rename targets: 4 Envoy (proto, .h, .cc, test), 4 K8s (types.go, grpc.go, prober.go, grpcaction.go)
- Weights: envoy=0.6 (proto source), kubernetes=0.4
- Files: instruction.md, task.toml, task.yaml, environment/Dockerfile, tests/test.sh, tests/expected_changes.json
- **Learnings for future iterations:**
  - Envoy proto field: api/envoy/config/core/v3/health_check.proto GrpcHealthCheck.service_name
  - K8s Go struct: staging/src/k8s.io/api/core/v1/types.go GRPCAction.Service
  - Both reference gRPC health spec; different field names (service_name vs service)
  - K8s has many generated files (pb.go, deepcopy, conversion) that should NOT be manually edited
  - Envoy C++ uses service_name_ member in health_checker_impl.h/cc
---

## 2026-01-31 - US-006
- Created `benchmarks/10figure/cross_bug_localization_01/` task package (Kubernetes + Django)
- Task: locate TOCTOU race conditions in K8s DeltaFIFO (syncKeyLocked/Replace) and Django db cache (_base_set add mode)
- Bug locations: K8s delta_fifo.go syncKeyLocked len(f.items[id])>0 check; Django db.py _base_set SELECT→INSERT race
- Includes correct implementation contrast (Django locmem.py add() with _lock)
- Weights: kubernetes=0.55, django=0.45 (K8s has more bug locations)
- Files: instruction.md, task.toml, task.yaml, environment/Dockerfile, tests/test.sh, tests/expected_changes.json
- **Learnings for future iterations:**
  - K8s DeltaFIFO is in staging/src/k8s.io/client-go/tools/cache/delta_fifo.go (not pkg/)
  - Django cache backends are in django/core/cache/backends/ with db.py (database), locmem.py (in-memory), memcached.py
  - The code comments in K8s acknowledge the race condition explicitly
  - Django's DatabaseError silencing in _base_set is documented as intentional for thread safety
---

## 2026-01-31 - US-005
- Created `benchmarks/10figure/cross_dependency_impact_01/` task package (Django + TensorFlow)
- Task analyzes JSON serialization incompatibilities: DjangoJSONEncoder vs TF get_json_type
- 7 ground truth symbols (4 Django, 3 TF), 4 incompatible types (numpy.ndarray, numpy.float32, TensorShape, datetime)
- Files: instruction.md, task.toml, task.yaml, environment/Dockerfile, tests/test.sh, tests/expected_changes.json
- **Learnings for future iterations:**
  - Django JSON encoder handles: datetime, date, time, timedelta, Decimal, UUID, Promise
  - TF json_utils handles: numpy (module check + tolist/item), TensorShape, DType, TypeSpec, tuples
  - The cross-repo connection is incompatibility-based, not API coupling
  - DjangoJSONEncoder in django/core/serializers/json.py; TF Encoder in tensorflow/python/keras/saving/saved_model/json_utils.py
---

## 2026-01-31 - US-004
- Created `benchmarks/10figure/cross_api_tracing_01/` task package (Kubernetes + Envoy)
- Task traces `appProtocol` from K8s ServicePort/EndpointPort → Envoy FilterChainMatch/ClusterProtocolSelection
- 7 ground truth symbols: ServicePort.AppProtocol, EndpointPort.AppProtocol, ValidateQualifiedName, FilterChainMatch.application_protocols, TlsInspector.onALPN, ClusterProtocolSelection, Cluster.protocol_selection
- Scoring: 60% symbol coverage (per-repo weighted 50/50), 40% keyword coverage
- Files: instruction.md, task.toml, task.yaml, environment/Dockerfile, tests/test.sh, tests/expected_changes.json
- **Learnings for future iterations:**
  - Cross-repo connection between K8s and Envoy is implicit (via control plane like Istio), not direct API coupling
  - K8s appProtocol is in pkg/apis/core/types.go (ServicePort) and staging/.../discovery/v1/types.go (EndpointPort)
  - Envoy protocol detection uses FilterChainMatch.application_protocols + TLS Inspector ALPN
  - pyyaml not available in system Python 3.14; use tomllib for TOML validation
---

## 2026-01-31 - US-008
- Created `benchmarks/10figure/scripts/validate_patch_cross_repo.py` with `--weights` argument support
- Wraps base `validate_patch.py` -- splits combined patch by repo, validates per-repo, computes weighted score
- Without `--weights`, delegates to base validator unchanged (single-repo fallback)
- Output JSON includes `overall_score` and `per_repo_scores` fields
- 11 unit tests in `tests/test_validate_patch_cross_repo.py` covering: weight validation, patch splitting, two-repo weighted scoring, partial coverage, single-repo fallback
- Files changed: `benchmarks/10figure/scripts/validate_patch_cross_repo.py`, `tests/test_validate_patch_cross_repo.py`, `prd.json`
- **Learnings for future iterations:**
  - Base validate_patch.py lives in external corpus at ~/10Figure-Codebases/scripts/ - don't modify it directly
  - Created wrapper script in benchmark dir instead of modifying corpus
  - Patch repo detection uses `/{repo_name}/` pattern in diff headers
  - Python 3.14 is available on this system (via Homebrew)
---

## 2026-01-31 - US-003
- Created `benchmarks/10figure/templates/cross_repo_test.sh.j2` for cross-repo task validation
- Template splits combined patch into per-repo patches, validates each with validate_patch.py, computes weighted score
- Template variable `repo_weights` accepts "repo_name:weight repo_name:weight" format (e.g., "kubernetes:0.6 envoy:0.4")
- Writes per-repo breakdown to `/logs/verifier/validation_result.json` and combined reward to `/logs/verifier/reward.txt`
- Files changed: `benchmarks/10figure/templates/cross_repo_test.sh.j2`, `prd.json`
- **Learnings for future iterations:**
  - Patch splitting detects repo by looking for `/{repo_name}/` in diff headers (e.g., `diff --git a/src/kubernetes/...`)
  - Weight validation ensures sum is 1.0 (with 0.01 tolerance for floating point)
  - Per-repo validation runs validate_patch.py with `cwd` set to the repo directory
  - Template uses inline Python scripts rather than external scripts for portability in containers
---

## 2026-01-31 - US-002
- Rewrote `benchmarks/10figure/base/Dockerfile` as multi-stage build (builder strips .git + copies only 4 target repos; runtime installs deps)
- Updated `benchmarks/10figure/base/build.sh` with validation for all 4 repos and image size reporting
- Added pinned commit SHA env vars (KUBERNETES_SHA, ENVOY_SHA, DJANGO_SHA, TENSORFLOW_SHA)
- Files changed: `benchmarks/10figure/base/Dockerfile`, `benchmarks/10figure/base/build.sh`, `prd.json`
- **Learnings for future iterations:**
  - The corpus .git dirs are small (~195MB total) since repos are shallow/partial clones
  - 4 target repos total ~1.1GB source; full corpus is 3.6GB (has 24 repos total)
  - Multi-stage build discards builder layer, so .git stripping and intermediate copies don't add to final image
  - build.sh uses podman (not docker) - check `podman` availability on target system
---

## 2026-01-31 - US-001
- Resolved all 4 open questions in `tasks/prd-10figure-benchmark-expansion.md`
- Pinned commit SHAs from local 10Figure-Codebases corpus: kubernetes=ef274e86, envoy=782c6cae, django=c4e07f94, tensorflow=420baf67
- Decisions: single combined patch, existing corpus-copy image strategy, per-repo weighted scoring
- Files changed: `tasks/prd-10figure-benchmark-expansion.md`, `prd.json`, `progress.txt`
- **Learnings for future iterations:**
  - sg-benchmarks org only has kubernetes--latest and django SWE-bench mirrors; envoy and tensorflow need new mirrors for MCP indexing
  - The corpus is pre-built externally (not cloned inside Docker); base image just copies it in
  - No tags in the corpus repos (shallow/partial clones), so `git describe --tags` fails; use commit SHA directly
---

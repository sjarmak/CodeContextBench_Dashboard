```rust
//! src/module_24.rs
//!
//! Event-bus implementation used across EduPulse Live.
//!
//! Responsibilities:
//! 1. Wrap domain occurrences in rich envelopes that carry trace metadata.
//! 2. Persist envelopes in the event-store (PostgreSQL) for replay / audits.
//! 3. Publish the envelope to the broker (RabbitMQ) for downstream workers.
//!
//! NOTE: In production this module lives in its own crate (`edupulse-event-bus`);
//!       the code is inlined here for brevity.

use std::{fmt, sync::Arc};

use async_trait::async_trait;
use chrono::{DateTime, Utc};
use lapin::{
    options::BasicPublishOptions,
    publisher_confirm::Confirmation,
    types::FieldTable,
    BasicProperties, Channel, Connection, ConnectionProperties,
};
use serde::{Deserialize, Serialize};
use thiserror::Error;
use tokio_postgres::{NoTls, Row};
use tracing::{info, instrument, warn};
use uuid::Uuid;

/// Unique identifier carried by every envelope for distributed tracing.
#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash, Serialize, Deserialize)]
pub struct CorrelationId(Uuid);

impl CorrelationId {
    pub fn new() -> Self {
        Self(Uuid::new_v4())
    }
}

/// Top-level domain events used in the MVP.
/// New events should be added in backward-compatible manner: never delete or
/// repurpose variants to preserve event-store integrity.
#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(tag = "type", content = "data")]
pub enum DomainEvent {
    LessonPublished {
        lesson_id: Uuid,
        teacher_id: Uuid,
        title: String,
    },
    QuizSubmitted {
        quiz_id: Uuid,
        learner_id: Uuid,
        score_raw: i32,
    },
    BadgeAwarded {
        badge_id: Uuid,
        recipient_id: Uuid,
        reason: String,
    },
    // keep enum non-exhaustive for forward compatibility
    #[serde(other)]
    Unknown,
}

/// Envelope wrapping domain events with metadata needed at infrastructure
/// boundaries (idempotency, ordering, traceability, etc.).
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct EventEnvelope {
    /// Unique, monotonically increasing snowflake-like id. Generated by DB.
    pub id: Option<i64>,
    /// Timestamp (UTC) at which the event occurred.
    pub occurred_at: DateTime<Utc>,
    /// Correlation id used to stitch together all logs for a request.
    pub correlation_id: CorrelationId,
    /// Actual business event.
    pub payload: DomainEvent,
}

impl EventEnvelope {
    pub fn new(payload: DomainEvent, correlation_id: CorrelationId) -> Self {
        Self {
            id: None,
            occurred_at: Utc::now(),
            correlation_id,
            payload,
        }
    }
}

/* -------------------------- Error Definitions --------------------------- */

#[derive(Debug, Error)]
pub enum EventBusError {
    #[error("database failure: {0}")]
    Db(#[from] tokio_postgres::Error),
    #[error("broker failure: {0}")]
    Broker(#[from] lapin::Error),
    #[error("publishing not confirmed by broker")]
    NoBrokerAck,
}

/* ----------------------------- Event Store ------------------------------ */

/// Persist events for replay / audit.
///
/// We use `tokio-postgres` directly; in production we wrap this in a small
/// repository layer or use `sqlx` for compile-time queries.
pub struct PgEventStore {
    client: tokio_postgres::Client,
}

impl PgEventStore {
    pub async fn connect(pg_url: &str) -> Result<Self, EventBusError> {
        let (client, connection) = tokio_postgres::connect(pg_url, NoTls).await?;
        // Spawn the connection task so it keeps handling messages.
        tokio::spawn(async move {
            if let Err(err) = connection.await {
                warn!(error = %err, "pg connection closed unexpectedly");
            }
        });

        // Ensure the events table exists.
        client
            .batch_execute(
                r#"
                create table if not exists event_store (
                    id bigserial primary key,
                    occurred_at timestamptz not null,
                    correlation_id uuid not null,
                    payload jsonb not null
                );

                create index if not exists idx_event_store_corr
                    on event_store (correlation_id);
                "#,
            )
            .await?;

        Ok(Self { client })
    }

    #[instrument(skip_all, err)]
    pub async fn persist(&self, mut envelope: EventEnvelope) -> Result<EventEnvelope, EventBusError> {
        let stmt = self
            .client
            .prepare_cached(
                "insert into event_store (occurred_at, correlation_id, payload)
                 values ($1, $2, $3)
                 returning id",
            )
            .await?;

        let payload_json = serde_json::to_value(&envelope.payload).expect("serialization never fails");

        let row: Row = self
            .client
            .query_one(&stmt, &[&envelope.occurred_at, &envelope.correlation_id.0, &payload_json])
            .await?;

        envelope.id = Some(row.get::<_, i64>("id"));
        Ok(envelope)
    }
}

/* ------------------------ AMQP Event Publisher -------------------------- */

/// Publish events to RabbitMQ exchange `edupulse.events`.
pub struct AmqpPublisher {
    channel: Channel,
    exchange: String,
}

impl AmqpPublisher {
    pub async fn connect(uri: &str, exchange: &str) -> Result<Self, EventBusError> {
        // `ConnectionProperties` includes tokio reactor integration by default.
        let conn = Connection::connect(uri, ConnectionProperties::default()).await?;
        let channel = conn.create_channel().await?;

        // Ensure exchange is declared (idempotent).
        channel
            .exchange_declare(
                exchange,
                lapin::ExchangeKind::Topic,
                lapin::options::ExchangeDeclareOptions::default(),
                FieldTable::default(),
            )
            .await?;

        Ok(Self {
            channel,
            exchange: exchange.to_string(),
        })
    }
}

#[async_trait]
pub trait EventPublisher: Send + Sync {
    async fn publish(&self, envelope: &EventEnvelope) -> Result<(), EventBusError>;
}

#[async_trait]
impl EventPublisher for AmqpPublisher {
    #[instrument(skip_all, err)]
    async fn publish(&self, envelope: &EventEnvelope) -> Result<(), EventBusError> {
        let routing_key = match &envelope.payload {
            DomainEvent::LessonPublished { .. } => "lesson.published",
            DomainEvent::QuizSubmitted { .. } => "quiz.submitted",
            DomainEvent::BadgeAwarded { .. } => "badge.awarded",
            DomainEvent::Unknown => "unknown",
        };

        // Safety: serde_json never fails for valid Serialize.
        let data = serde_json::to_vec(envelope).expect("serialize envelope");

        let confirm: Confirmation = self
            .channel
            .basic_publish(
                &self.exchange,
                routing_key,
                BasicPublishOptions::default(),
                &data,
                BasicProperties::default().with_content_type("application/json".into()),
            )
            .await?
            .await?; // wait for broker ack

        if confirm.is_nack() {
            return Err(EventBusError::NoBrokerAck);
        }

        Ok(())
    }
}

/* ------------------------------ EventBus -------------------------------- */

/// Facade that atomically persists and publishes an event.
///
/// A two-phase strategy is employed:
/// 1. Persist event to DB (obtaining an id to guarantee ordering).
/// 2. Publish to broker.
/// Should the broker be down, the event is still in the DB and can be replayed.
#[derive(Clone)]
pub struct EventBus {
    store: Arc<PgEventStore>,
    publisher: Arc<dyn EventPublisher>,
}

impl fmt::Debug for EventBus {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        f.debug_struct("EventBus").finish_non_exhaustive()
    }
}

impl EventBus {
    pub fn new(store: PgEventStore, publisher: impl EventPublisher + 'static) -> Self {
        Self {
            store: Arc::new(store),
            publisher: Arc::new(publisher),
        }
    }

    #[instrument(skip(self), err, fields(event_type = ?event))]
    pub async fn dispatch(
        &self,
        event: DomainEvent,
        correlation_id: Option<CorrelationId>,
    ) -> Result<EventEnvelope, EventBusError> {
        let corr_id = correlation_id.unwrap_or_else(CorrelationId::new);

        let envelope = EventEnvelope::new(event, corr_id);

        // 1. Persist.
        let saved = self.store.persist(envelope).await?;

        // 2. Publish.
        self.publisher.publish(&saved).await?;

        info!(
            id = saved.id.unwrap_or_default(),
            "event persisted & published"
        );

        Ok(saved)
    }
}

/* ------------------------------ Example --------------------------------- */

#[cfg(test)]
mod tests {
    use super::*;
    use std::env;

    #[tokio::test]
    async fn integration_smoke_test() -> Result<(), Box<dyn std::error::Error>> {
        // Skip unless integration env vars are present.
        let pg_url = match env::var("PG_URL") {
            Ok(v) => v,
            Err(_) => return Ok(()),
        };
        let amqp_url = env::var("AMQP_URL").unwrap_or_else(|_| "amqp://guest:guest@localhost:5672".into());

        let store = PgEventStore::connect(&pg_url).await?;
        let publisher = AmqpPublisher::connect(&amqp_url, "edupulse.events").await?;
        let bus = EventBus::new(store, publisher);

        let evt = DomainEvent::LessonPublished {
            lesson_id: Uuid::new_v4(),
            teacher_id: Uuid::new_v4(),
            title: "Rust Ownership Masterclass".into(),
        };

        let envelope = bus.dispatch(evt, None).await?;
        assert!(envelope.id.is_some());

        Ok(())
    }
}
```
```rust
//! src/module_58.rs
//!
//! Learning Pulse domain module.
//!
//! Responsibilities
//! 1. Persist `LearningPulse` aggregates in the relational store via `sqlx` (repository pattern).
//! 2. Publish canonical domain events to the event bus (NATS) after successful commits.
//! 3. Expose an application service API that the HTTP layer can invoke.
//!
//! NOTE:  
//! • The module is self-contained so it can be copy-pasted into the workspace until proper
//!   crate boundaries are laid out.  
//! • Replace feature flags or concrete implementations (e.g. NATS) as your infrastructure
//!   requires.

#![allow(dead_code)]

use async_nats::jetstream::{self, stream::PublishAck};
use async_trait::async_trait;
use chrono::{DateTime, Utc};
use futures::TryFutureExt;
use serde::{Deserialize, Serialize};
use sqlx::{PgPool, Postgres, QueryBuilder, Transaction};
use thiserror::Error;
use tokio::sync::mpsc;
use tracing::{debug, error, info};
use uuid::Uuid;

/// Strong-typed ID wrappers make it impossible to mix identifiers.
#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash, Serialize, Deserialize)]
pub struct PulseId(Uuid);

#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash, Serialize, Deserialize)]
pub struct UserId(Uuid);

impl PulseId {
    pub fn new() -> Self {
        Self(Uuid::new_v4())
    }
}
impl UserId {
    pub fn new() -> Self {
        Self(Uuid::new_v4())
    }
}

/// Aggregate root
#[derive(Debug, Clone)]
pub struct LearningPulse {
    pub id: PulseId,
    pub author_id: UserId,
    pub title: String,
    pub body: String,
    pub created_at: DateTime<Utc>,
    pub updated_at: DateTime<Utc>,
}

impl LearningPulse {
    pub fn new(author_id: UserId, title: impl Into<String>, body: impl Into<String>) -> Self {
        let now = Utc::now();
        Self {
            id: PulseId::new(),
            author_id,
            title: title.into(),
            body: body.into(),
            created_at: now,
            updated_at: now,
        }
    }
}

/// Canonical domain events ----------------------------------------------------
#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(tag = "type", rename_all = "snake_case")]
pub enum PulseEvent {
    PulseCreated(PulseCreated),
    PulseUpdated(PulseUpdated),
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct PulseCreated {
    pub pulse_id: PulseId,
    pub author_id: UserId,
    pub title: String,
    pub created_at: DateTime<Utc>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct PulseUpdated {
    pub pulse_id: PulseId,
    pub title: String,
    pub body: String,
    pub updated_at: DateTime<Utc>,
}

/// Repository abstraction -----------------------------------------------------
#[async_trait]
pub trait PulseRepository: Send + Sync + 'static {
    async fn insert(
        &self,
        tx: &mut Transaction<'_, Postgres>,
        pulse: &LearningPulse,
    ) -> Result<(), RepoError>;
    async fn update(
        &self,
        tx: &mut Transaction<'_, Postgres>,
        pulse: &LearningPulse,
    ) -> Result<(), RepoError>;
    async fn find_by_id(&self, id: PulseId) -> Result<Option<LearningPulse>, RepoError>;
}

#[derive(Debug, Error)]
pub enum RepoError {
    #[error("database error: {0}")]
    Sqlx(#[from] sqlx::Error),
}

/// Postgres implementation (sqlx) --------------------------------------------
pub struct PostgresPulseRepository {
    pool: PgPool,
}

impl PostgresPulseRepository {
    pub fn new(pool: PgPool) -> Self {
        Self { pool }
    }
}

#[async_trait]
impl PulseRepository for PostgresPulseRepository {
    async fn insert(
        &self,
        tx: &mut Transaction<'_, Postgres>,
        pulse: &LearningPulse,
    ) -> Result<(), RepoError> {
        sqlx::query!(
            r#"
            INSERT INTO learning_pulse(id, author_id, title, body, created_at, updated_at)
            VALUES($1, $2, $3, $4, $5, $6)
            "#,
            pulse.id.0,
            pulse.author_id.0,
            pulse.title,
            pulse.body,
            pulse.created_at,
            pulse.updated_at
        )
        .execute(&mut *tx)
        .await?;
        Ok(())
    }

    async fn update(
        &self,
        tx: &mut Transaction<'_, Postgres>,
        pulse: &LearningPulse,
    ) -> Result<(), RepoError> {
        sqlx::query!(
            r#"
            UPDATE learning_pulse
            SET title = $2, body = $3, updated_at = $4
            WHERE id = $1
            "#,
            pulse.id.0,
            pulse.title,
            pulse.body,
            pulse.updated_at
        )
        .execute(&mut *tx)
        .await?;
        Ok(())
    }

    async fn find_by_id(&self, id: PulseId) -> Result<Option<LearningPulse>, RepoError> {
        let rec = sqlx::query!(
            r#"
            SELECT id, author_id, title, body, created_at, updated_at
            FROM learning_pulse
            WHERE id = $1
            "#,
            id.0
        )
        .fetch_optional(&self.pool)
        .await?;

        Ok(rec.map(|row| LearningPulse {
            id: PulseId(row.id),
            author_id: UserId(row.author_id),
            title: row.title,
            body: row.body,
            created_at: row.created_at,
            updated_at: row.updated_at,
        }))
    }
}

/// Event publisher abstraction ------------------------------------------------
#[async_trait]
pub trait EventPublisher: Send + Sync + 'static {
    async fn publish(&self, event: &PulseEvent) -> Result<(), PublishError>;
}

#[derive(Debug, Error)]
pub enum PublishError {
    #[error("serialization error: {0}")]
    Serialize(#[from] serde_json::Error),
    #[error("nats I/O error: {0}")]
    Nats(#[from] async_nats::Error),
}

/// JetStream-backed publisher (NATS) -----------------------------------------
pub struct NatsPublisher {
    subject: String,
    jetstream: jetstream::Context,
    acknowledger: mpsc::Sender<PublishAck>, // track acks in background task
}

impl NatsPublisher {
    pub async fn new(
        nats_url: &str,
        subject: impl Into<String>,
    ) -> Result<Self, async_nats::Error> {
        let client = async_nats::connect(nats_url).await?;
        let jetstream = jetstream::new(client);
        let (tx, mut rx) = mpsc::channel::<PublishAck>(32);

        // Spawn a background task that logs JetStream publish ACKs.
        tokio::spawn(async move {
            while let Some(ack) = rx.recv().await {
                match ack.await {
                    Ok(meta) => debug!("Event persisted to stream: {meta:?}"),
                    Err(err) => error!("Failed to persist event: {err}"),
                }
            }
        });

        Ok(Self {
            subject: subject.into(),
            jetstream,
            acknowledger: tx,
        })
    }
}

#[async_trait]
impl EventPublisher for NatsPublisher {
    async fn publish(&self, event: &PulseEvent) -> Result<(), PublishError> {
        let payload = serde_json::to_vec(event)?;
        let ack = self
            .jetstream
            .publish(self.subject.to_owned(), payload.into())
            .await?;
        // Fire-and-forget tracking of the ack so we don’t block callers.
        let _ = self.acknowledger.send(ack).await;
        Ok(())
    }
}

/// Service layer --------------------------------------------------------------
#[derive(Clone)]
pub struct LearningPulseService<R: PulseRepository, P: EventPublisher> {
    repo: R,
    publisher: P,
    pool: PgPool,
}

#[derive(Debug, Error)]
pub enum ServiceError {
    #[error(transparent)]
    Repo(#[from] RepoError),
    #[error(transparent)]
    Db(#[from] sqlx::Error),
    #[error(transparent)]
    Publish(#[from] PublishError),
    #[error("pulse not found")]
    NotFound,
}

impl<R: PulseRepository, P: EventPublisher> LearningPulseService<R, P> {
    pub fn new(repo: R, publisher: P, pool: PgPool) -> Self {
        Self {
            repo,
            publisher,
            pool,
        }
    }

    /// Create a new learning pulse and publish a `pulse_created` event.
    pub async fn create_pulse(
        &self,
        author_id: UserId,
        title: impl Into<String>,
        body: impl Into<String>,
    ) -> Result<PulseId, ServiceError> {
        let mut tx = self.pool.begin().await?;
        let pulse = LearningPulse::new(author_id, title, body);
        self.repo.insert(&mut tx, &pulse).await?;

        let event = PulseEvent::PulseCreated(PulseCreated {
            pulse_id: pulse.id,
            author_id: pulse.author_id,
            title: pulse.title.clone(),
            created_at: pulse.created_at,
        });

        tx.commit().await?;
        self.publisher.publish(&event).await?;
        info!("Created new pulse {} by {:?}", pulse.id.0, author_id.0);
        Ok(pulse.id)
    }

    /// Update existing pulse; returns error if pulse does not exist.
    pub async fn update_pulse(
        &self,
        pulse_id: PulseId,
        title: impl Into<String>,
        body: impl Into<String>,
    ) -> Result<(), ServiceError> {
        let mut tx = self.pool.begin().await?;
        let Some(mut pulse) = self.repo.find_by_id(pulse_id).await? else {
            return Err(ServiceError::NotFound);
        };

        pulse.title = title.into();
        pulse.body = body.into();
        pulse.updated_at = Utc::now();

        self.repo.update(&mut tx, &pulse).await?;
        let event = PulseEvent::PulseUpdated(PulseUpdated {
            pulse_id,
            title: pulse.title.clone(),
            body: pulse.body.clone(),
            updated_at: pulse.updated_at,
        });

        tx.commit().await?;
        self.publisher.publish(&event).await?;
        info!("Updated pulse {}", pulse_id.0);
        Ok(())
    }
}

/// Database schema migrations -------------------------------------------------
///
/// WARNING: In production, migrations must be applied using `sqlx migrate`.
/// The following helper ensures that the required table exists when running
/// tests or the local binary. It will **not** run in production clusters.
pub async fn ensure_schema(pool: &PgPool) -> Result<(), sqlx::Error> {
    let mut builder: QueryBuilder<Postgres> = QueryBuilder::new(
        r#"
        CREATE TABLE IF NOT EXISTS learning_pulse(
            id UUID PRIMARY KEY,
            author_id UUID NOT NULL,
            title TEXT NOT NULL,
            body TEXT NOT NULL,
            created_at TIMESTAMPTZ NOT NULL,
            updated_at TIMESTAMPTZ NOT NULL
        );
        "#,
    );
    builder.build().execute(pool).await?;
    Ok(())
}

/// ------------------------------ Tests ---------------------------------------
#[cfg(test)]
mod tests {
    use super::*;
    use std::time::Duration;

    struct InMemoryPublisher {
        tx: mpsc::Sender<PulseEvent>,
    }

    #[async_trait::async_trait]
    impl EventPublisher for InMemoryPublisher {
        async fn publish(&self, event: &PulseEvent) -> Result<(), PublishError> {
            self.tx
                .send(event.clone())
                .await
                .map_err(|_| async_nats::Error::from(std::io::ErrorKind::BrokenPipe))?;
            Ok(())
        }
    }

    #[sqlx::test(migrations = "../../migrations")]
    async fn pulse_crud(pool: PgPool) -> anyhow::Result<()> {
        ensure_schema(&pool).await?;

        let (tx, mut rx) = mpsc::channel(8);
        let repo = PostgresPulseRepository::new(pool.clone());
        let service = LearningPulseService::new(
            repo,
            InMemoryPublisher { tx },
            pool.clone(),
        );

        let author = UserId::new();
        let pulse_id = service
            .create_pulse(author, "Test Title", "Initial Body")
            .await?;

        // Wait for the async publish to propagate in the test.
        tokio::time::timeout(Duration::from_secs(1), rx.recv())
            .await?
            .expect("event should be published");

        service
            .update_pulse(pulse_id, "New Title", "Updated Body")
            .await?;

        Ok(())
    }
}
```
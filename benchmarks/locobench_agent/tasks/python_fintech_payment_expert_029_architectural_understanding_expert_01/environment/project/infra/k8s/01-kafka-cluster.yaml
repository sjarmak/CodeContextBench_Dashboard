```python
#!/usr/bin/env python3
"""
crowdpay_connect/infra/k8s/01-kafka-cluster.py
------------------------------------------------
Utility script that generates the Kubernetes manifest for the core Kafka
cluster used by the CrowdPay Connect platform.

The manifest follows Strimzi’s Kafka CRD schema and is **environment aware**.
Local, staging, and production environments may differ in replica counts,
persistence configuration, resource limits, and metrics settings.  This script
bundles best-practice defaults while allowing Ops-SRE teams to fine-tune via a
single YAML-overrides file or CLI flags.

Usage
-----
$ ./01-kafka-cluster.py --env prod --output 01-kafka-cluster.yaml

Dependencies
------------
pip install ruamel.yaml==0.17.*  (strictly pinned for reproducibility)

Security & Compliance
---------------------
All default listener configurations enforce TLS encryption.  SCRAM-SHA-512
authentication is enabled by default to meet PCI-DSS and SOC 2 controls.  The
cluster is labeled and annotated for CrowdPay’s continuous-compliance scanners.
"""
from __future__ import annotations

import argparse
import os
import sys
from dataclasses import dataclass, field
from datetime import datetime
from typing import Any, Dict, List

from ruamel.yaml import YAML
from ruamel.yaml.scalarstring import DoubleQuotedScalarString as DQ

__all__ = ["KafkaClusterConfig", "KafkaClusterManifestBuilder", "main"]


@dataclass
class KafkaClusterConfig:
    """
    Strongly-typed configuration model for the CrowdPay Kafka cluster.
    """
    env: str
    replicas_kafka: int
    replicas_zookeeper: int
    storage_size_gi: int
    cpu_limit: str
    memory_limit: str
    enable_metrics: bool = True
    kafka_version: str = "3.7.0"
    strimzi_version: str = "0.41.0"
    namespace: str = "crowdpay-connect"
    cluster_name: str = "crowdpay-kafka"
    image_registry: str = "quay.io/strimzi"
    authentication_type: str = "scram-sha-512"
    allowed_listener_hosts: List[str] = field(
        default_factory=lambda: ["*.crowdpay.internal", "*.crowdpay.local"]
    )

    @classmethod
    def from_env(cls, env: str) -> "KafkaClusterConfig":
        """
        Factory that yields sensible defaults per environment.
        """
        env = env.lower()
        if env not in ("local", "staging", "prod", "production"):
            raise ValueError(
                f"Unsupported environment '{env}'. "
                "Choose from: local, staging, prod."
            )

        if env == "local":
            return cls(
                env=env,
                replicas_kafka=1,
                replicas_zookeeper=1,
                storage_size_gi=5,
                cpu_limit="500m",
                memory_limit="1Gi",
                enable_metrics=False,  # de-saturated dev cluster
            )
        if env == "staging":
            return cls(
                env=env,
                replicas_kafka=3,
                replicas_zookeeper=3,
                storage_size_gi=20,
                cpu_limit="1",
                memory_limit="2Gi",
            )
        # production defaults
        return cls(
            env=env,
            replicas_kafka=5,
            replicas_zookeeper=5,
            storage_size_gi=100,
            cpu_limit="2",
            memory_limit="4Gi",
        )


class KafkaClusterManifestBuilder:
    """
    Builder that converts `KafkaClusterConfig` into a Strimzi Kafka CR manifest.
    """

    def __init__(self, config: KafkaClusterConfig) -> None:
        self.cfg = config
        self.yaml = YAML()
        self.yaml.explicit_start = True
        self.yaml.default_flow_style = False
        self.yaml.indent(sequence=4, offset=2)

    # --------------------------------------------------------------------- #
    # PUBLIC API
    # --------------------------------------------------------------------- #

    def build(self) -> Dict[str, Any]:
        """
        Produce the final manifest as a Python dictionary ready for YAML dump.
        """
        return {
            "apiVersion": "kafka.strimzi.io/v1beta2",
            "kind": "Kafka",
            "metadata": self._build_metadata(),
            "spec": self._build_spec(),
        }

    def dump(self, stream=sys.stdout) -> None:
        """
        Dump the manifest to the provided stream.
        """
        manifest = self.build()
        try:
            self.yaml.dump(manifest, stream)
        except Exception as exc:  # pragma: no cover
            # The ruamel serializer rarely fails, but explicit handling keeps
            # our CI happy and shields callers from partial writes.
            raise RuntimeError("Failed to serialize Kafka manifest") from exc

    # --------------------------------------------------------------------- #
    # INTERNAL HELPERS
    # --------------------------------------------------------------------- #

    def _build_metadata(self) -> Dict[str, Any]:
        """
        Compose Kubernetes metadata — includes CrowdPay compliance annotations.
        """
        return {
            "name": self.cfg.cluster_name,
            "namespace": self.cfg.namespace,
            "labels": {
                "app.kubernetes.io/name": "kafka",
                "app.kubernetes.io/part-of": "crowdpay-connect",
                "app.kubernetes.io/component": "infra",
                "app.kubernetes.io/version": self.cfg.kafka_version,
                "crowdpay.io/env": self.cfg.env,
            },
            "annotations": {
                "crowdpay.io/owner": "team-payments-platform",
                "crowdpay.io/created": datetime.utcnow()
                .replace(microsecond=0)
                .isoformat()
                + "Z",
            },
        }

    def _build_spec(self) -> Dict[str, Any]:
        """
        Build the 'spec' section per Strimzi’s CRD schema.
        """
        return {
            "kafka": {
                "version": self.cfg.kafka_version,
                "replicas": self.cfg.replicas_kafka,
                "listeners": self._build_listeners(),
                "config": self._broker_config(),
                "storage": self._storage(),
                "resources": self._resources(),
                "authorization": {"type": "simple"},
            },
            "zookeeper": {
                "replicas": self.cfg.replicas_zookeeper,
                "storage": self._storage(),
                "resources": self._resources(),
            },
            "entityOperator": {
                "topicOperator": {},
                "userOperator": {},
            },
        }

    def _build_listeners(self) -> List[Dict[str, Any]]:
        """
        Expose TLS listeners with SCRAM auth.  CrowdPay has no plain listeners.
        """
        return [
            {
                "name": "tls",
                "port": 9093,
                "type": "internal",
                "tls": True,
                "authentication": {"type": self.cfg.authentication_type},
            },
            {
                "name": "external",
                "port": 9094,
                "type": "route"
                if self.cfg.env == "prod"
                else "nodeport",
                "tls": True,
                "authentication": {"type": self.cfg.authentication_type},
                "configuration": {
                    "brokerCertChainAndKey": {
                        "secretName": f"{self.cfg.cluster_name}-cluster-ca-cert",
                        "certificate": "ca.crt",
                        "key": "ca.key",
                    },
                    "host": DQ(",".join(self.cfg.allowed_listener_hosts)),
                },
            },
        ]

    def _broker_config(self) -> Dict[str, Any]:
        """
        Fine-grained broker tunables – partition limits, replication factors,
        feature flags, etc.
        """
        base: Dict[str, Any] = {
            "offsets.topic.replication.factor": 3,
            "transaction.state.log.replication.factor": 3,
            "transaction.state.log.min.isr": 2,
            "auto.create.topics.enable": "false",
            "min.insync.replicas": 2,
            "log.message.format.version": self.cfg.kafka_version,
            # Force TLS cipher suites aligned with CrowdPay’s security baseline
            "ssl.enabled.protocols": "TLSv1.2,TLSv1.3",
            "ssl.endpoint.identification.algorithm": "",
        }

        # Local env can lower replication to save disk
        if self.cfg.env == "local":
            base["offsets.topic.replication.factor"] = 1
            base["transaction.state.log.replication.factor"] = 1
            base["min.insync.replicas"] = 1

        # Metrics reporter (Prometheus JMX exporter sidecar) toggle
        if self.cfg.enable_metrics:
            base["metrics.enabled"] = "true"

        return base

    def _storage(self) -> Dict[str, Any]:
        """
        Persistent storage definition.  Uses Tolerations-friendly SSD class.
        """
        return {
            "type": "jbod",
            "volumes": [
                {
                    "id": 0,
                    "type": "persistent-claim",
                    "size": f"{self.cfg.storage_size_gi}Gi",
                    "deleteClaim": False,
                    "class": "fast-ssd",
                }
            ],
        }

    def _resources(self) -> Dict[str, Any]:
        """
        Compute resource requests/limits to guarantee QoS 'Guaranteed' class.
        """
        cpu = self.cfg.cpu_limit
        mem = self.cfg.memory_limit
        return {
            "requests": {"cpu": cpu, "memory": mem},
            "limits": {"cpu": cpu, "memory": mem},
        }


# ------------------------------------------------------------------------- #
# CLI ENTRY-POINT
# ------------------------------------------------------------------------- #
def parse_args(argv: List[str]) -> argparse.Namespace:
    parser = argparse.ArgumentParser(
        description="Generate Strimzi Kafka cluster manifest for CrowdPay Connect."
    )
    parser.add_argument(
        "--env",
        required=True,
        choices=["local", "staging", "prod"],
        help="Target environment that influences replicas and resources.",
    )
    parser.add_argument(
        "--output",
        "-o",
        metavar="FILE",
        help="Write the YAML output to FILE instead of stdout.",
    )
    return parser.parse_args(argv)


def main(argv: List[str] | None = None) -> None:
    args = parse_args(argv or sys.argv[1:])
    config = KafkaClusterConfig.from_env(args.env)
    builder = KafkaClusterManifestBuilder(config)

    # Determine output medium
    if args.output:
        out_path = os.path.abspath(args.output)
        try:
            with open(out_path, "w", encoding="utf-8") as fh:
                builder.dump(fh)
            print(f"Kafka manifest written to: {out_path}", file=sys.stderr)
        except OSError as exc:
            raise SystemExit(f"Failed to write output file: {exc}") from exc
    else:
        builder.dump(sys.stdout)


if __name__ == "__main__":
    main()
```
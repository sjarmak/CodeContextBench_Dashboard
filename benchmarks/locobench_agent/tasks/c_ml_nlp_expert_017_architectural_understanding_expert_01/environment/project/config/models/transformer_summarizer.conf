# ---------------------------------------------------------------------------
# LexiLearn Orchestrator – Transformer Summarizer Configuration
# File: lexilearn_orchestrator/config/models/transformer_summarizer.conf
#
# This configuration drives the end-to-end life-cycle of the Transformer-based
# summarization model used throughout the LexiLearn MVC platform.  It is
# consumed by the C-based orchestration layer, which parses this file via the
# shared “lexi_cfg” library (liblexicfg.so) and mounts the parameters into
# training/inference jobs, monitoring daemons, and MLOps pipelines.
#
# Syntax: INI-style key=value pairs with section headers.
# All durations follow the ISO-8601 notation unless explicitly stated.
# ---------------------------------------------------------------------------

##############################################################################
# MODEL METADATA
##############################################################################
[model]
name                    = transformer_summarizer          # Unique model identifier
version                 = 1.2.0                           # Semantic version (major.minor.patch)
strategy                = TRANSFORMER                     # Plugs into Strategy Pattern
description             = Summarizes long-form student essays and LMS logs
author                  = LexiLearn Research Team
created_at              = 2024-05-28T09:00:00Z            # RFC-3339 timestamp

##############################################################################
# ARCHITECTURE / HYPERPARAMETERS
##############################################################################
[transformer]
backbone                = allenai/longformer-base-4096
max_seq_length          = 4096
num_hidden_layers       = 12
num_attention_heads     = 12
hidden_size             = 768
intermediate_size       = 3072
dropout_prob            = 0.10
attention_dropout_prob  = 0.10
initializer_range       = 0.02

##############################################################################
# TRAINING CONFIGURATION
##############################################################################
[training]
batch_size                      = 8
gradient_accumulation_steps     = 8
num_epochs                      = 4
learning_rate                   = 3e-5
weight_decay                    = 0.01
warmup_steps                    = 1500
max_grad_norm                   = 1.0
seed                            = 42
optimizer                       = adamw
scheduler                       = linear
mixed_precision                 = true        # Enable FP16/FP32 mixed precision

##############################################################################
# DATA PIPELINE
##############################################################################
[data]
dataset_name            = lexilearn_summaries
feature_store_table     = summaries_feature_table
input_field             = document
output_field            = summary
train_split             = 0.80
val_split               = 0.10
test_split              = 0.10
shuffle                 = true
min_tokens_per_doc      = 200
sticky_session_window   = P30D             # Keep student sessions grouped within 30-day window

##############################################################################
# CALLBACKS / CHECKPOINTS
##############################################################################
[callbacks]
early_stopping_patience = 3
log_every_n_steps       = 50
save_checkpoints        = true
checkpoint_dir          = /var/lexilearn/checkpoints/transformer_summarizer
best_model_metric       = rougeL
max_checkpoints_to_keep = 5

##############################################################################
# MONITORING & DRIFT DETECTION
##############################################################################
[monitoring]
metrics                 = rouge1, rougeL, bertscore_f1
drift_threshold         = 0.05              # Trigger when metric drops >5 %
monitor_refresh_rate    = PT1H             # Evaluate every hour
alert_channel           = slack://#ml-alerts

##############################################################################
# MODEL REGISTRY / VERSIONING
##############################################################################
[versioning]
registry_uri            = mlflow:http://registry.lexilearn.edu
model_registry_stage    = Production
enable_rollback         = true
artifact_retention_days = 90

##############################################################################
# AUTOMATED RETRAINING SCHEDULE
##############################################################################
[retraining]
enable                  = true
retraining_window       = P7D              # Look-back window for new data
min_data_increment      = 5000             # Minimum new samples before retraining
schedule_cron           = 0 3 * * SUN      # Every Sunday at 03:00
max_concurrent_runs     = 1

##############################################################################
# HYPERPARAMETER TUNING (MLOps / BAYESIAN OPTIMIZATION)
##############################################################################
[tuning]
enable                  = true
method                  = bayesian
max_trials              = 40
parallel_trials         = 4
metric                  = val/rougeL
goal                    = maximize
search_space.learning_rate      = loguniform(1e-6, 5e-5)
search_space.weight_decay       = uniform(0.0, 0.15)
search_space.dropout_prob       = uniform(0.05, 0.30)
search_space.num_hidden_layers  = int(6, 16)
search_space.num_attention_heads= int(8, 16)

##############################################################################
# SECURITY / COMPLIANCE
##############################################################################
[security]
allowlist_domains       = lexilearn.edu, district42.edu
encryption_key          = env:LEXILEARN_ENCRYPTION_KEY
mask_sensitive_data     = true
pii_redaction_level     = strict

##############################################################################
# LOGGING
##############################################################################
[logging]
level                   = INFO
log_dir                 = /var/log/lexilearn
rotation                = daily
retention_days          = 30

##############################################################################
# END OF FILE
##############################################################################
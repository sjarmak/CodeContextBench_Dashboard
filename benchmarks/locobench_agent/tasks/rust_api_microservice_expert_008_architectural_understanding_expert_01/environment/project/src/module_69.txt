```rust
//! LedgerLink Nexus – Response Caching Module
//! ------------------------------------------
//! This module provides a production-ready, Redis-backed response–caching
//! middleware that is aware of multi-tenant boundaries and API versioning.
//!
//! Why in `module_69.txt`?  
//! In the real repository this would live in `src/middleware/response_cache.rs`,
//! but for the purpose of this prompt we keep everything self-contained.
//
// Features
// --------
// * SHA-256-based cache-key derivation that guarantees unique entries per
//   tenant, endpoint, query params and API version.
// * Pluggable TTL & stale-while-revalidate semantics.
// * Structured error handling compatible with the crate-wide `ApiError` type.
// * Async/await friendly (uses `tokio` + `deadpool-redis`).
// * Optional cache-bypass via `Cache-Control: no-cache` request header.
// * Generates strong ETags automatically for fresh writes.
//
// Usage
// -----
// (Pseudo)
// ````rust
// let cache = RedisResponseCache::new(redis_pool, CacheConfig::default());
// let maybe_payload = cache.try_get::<InvoiceList>(CacheKey::from_request(&req, tenant_id, 1)).await?;
// if let Some(payload) = maybe_payload {
//     return Ok(payload)                 // <- cache-hit
// }
// // fetch_from_db();
// cache.store(&key, &payload).await?;    // <- cache-miss, write-through
// ````

#![allow(clippy::missing_errors_doc)]

use std::time::{Duration, SystemTime};

use async_trait::async_trait;
use deadpool_redis::{
    redis::{self, AsyncCommands, FromRedisValue, ToRedisArgs},
    Connection, Pool,
};
use http::{header, HeaderMap, Method, Request, StatusCode};
use ring::digest::{Context, SHA256};
use serde::{de::DeserializeOwned, Serialize};
use thiserror::Error;
use tokio::time::timeout;

/// Public re-exports so downstream crates can depend on a single module.
pub use deadpool_redis::Pool as RedisPool;

//
// --------------------------- Error Handling ------------------------------
//
#[derive(Debug, Error)]
pub enum CacheError {
    #[error("redis error: {0}")]
    Redis(#[from] redis::RedisError),

    #[error("serialization error: {0}")]
    Serde(#[from] serde_json::Error),

    #[error("timeout after {0:?}")]
    Timeout(Duration),
}

pub type Result<T> = std::result::Result<T, CacheError>;

//
// --------------------------- Cache Config --------------------------------
//
#[derive(Clone, Debug)]
pub struct CacheConfig {
    /// Default time-to-live for cache entries.
    pub ttl: Duration,
    /// Time window in which stale values may be served while a background
    /// revalidation is happening.
    pub stale_while_revalidate: Duration,
    /// Namespace to avoid key collisions across envs (e.g. "dev", "prod").
    pub namespace: String,
    /// If true, debug logging will be emitted.
    pub verbose: bool,
}

impl Default for CacheConfig {
    fn default() -> Self {
        Self {
            ttl: Duration::from_secs(60),
            stale_while_revalidate: Duration::from_secs(30),
            namespace: "nexus".into(),
            verbose: false,
        }
    }
}

//
// --------------------------- Cache Key -----------------------------------
//
#[derive(Clone, Debug, Eq, PartialEq, Hash)]
pub struct CacheKey {
    pub tenant_id: String,
    pub api_version: u16,
    pub endpoint: String,
    pub params_hash: String,
}

impl CacheKey {
    /// Creates a `CacheKey` from an incoming HTTP request.
    pub fn from_request<B>(
        req: &Request<B>,
        tenant_id: &str,
        api_version: u16,
    ) -> Self {
        let endpoint = req.uri().path().to_owned();
        let params_hash = Self::hash_params(req.uri().query().unwrap_or_default());
        Self {
            tenant_id: tenant_id.to_owned(),
            api_version,
            endpoint,
            params_hash,
        }
    }

    /// Stable string representation (`namespace:key`).
    pub fn to_redis_key(&self, cfg: &CacheConfig) -> String {
        format!(
            "{}:v{}:{}:{}:{}",
            cfg.namespace,                        // ns guard
            self.api_version,                     // version guard
            self.tenant_id,                       // multi-tenant guard
            self.endpoint,                        // resource
            self.params_hash                      // idempotent hash
        )
    }

    fn hash_params(qs: &str) -> String {
        let mut ctx = Context::new(&SHA256);
        ctx.update(qs.as_bytes());
        let digest = ctx.finish();
        hex::encode(digest.as_ref())
    }
}

//
// --------------------------- Trait Definition ----------------------------
//
#[async_trait]
pub trait ResponseCache {
    /// Attempt to recover a cached value. `None` => cache-miss.
    async fn try_get<T>(&self, key: &CacheKey) -> Result<Option<CachedEnvelope<T>>>
    where
        T: DeserializeOwned + Send;

    /// Persist a new value in the cache.
    async fn store<T>(&self, key: &CacheKey, value: &T) -> Result<()>
    where
        T: Serialize + Send + Sync;

    /// Invalidate a cache entry immediately.
    async fn invalidate(&self, key: &CacheKey) -> Result<()>;
}

//
// --------------------------- Envelope -----------------------------------
//
/// Metadata wrapper – adds ETag & creation timestamp to the payload.
#[derive(Serialize, Deserialize, Debug)]
pub struct CachedEnvelope<T> {
    pub payload: T,
    pub etag: String,
    pub created_at: u64, // epoch millis
}

impl<T> CachedEnvelope<T> {
    fn new(payload: T) -> Result<Self>
    where
        T: Serialize,
    {
        // JSON serialize for hashing – produces deterministic ETag.
        let as_bytes = serde_json::to_vec(&payload)?;
        let mut ctx = Context::new(&SHA256);
        ctx.update(&as_bytes);
        let etag = base64::encode(ctx.finish().as_ref());
        Ok(Self {
            payload,
            etag,
            created_at: SystemTime::now()
                .duration_since(SystemTime::UNIX_EPOCH)
                .expect("system clock before 1970")
                .as_millis() as u64,
        })
    }

    /// Check if the entry is fresh given the requested TTL.
    fn is_fresh(&self, cfg: &CacheConfig) -> bool {
        let age = Duration::from_millis(
            (SystemTime::now()
                .duration_since(SystemTime::UNIX_EPOCH)
                .expect("clock")
                .as_millis() as u64)
                - self.created_at,
        );
        age <= cfg.ttl
    }
}

//
// -------------------- Concrete Redis Implementation ----------------------
//
pub struct RedisResponseCache {
    pool: Pool,
    cfg: CacheConfig,
}

impl RedisResponseCache {
    pub fn new(pool: Pool, cfg: CacheConfig) -> Self {
        Self { pool, cfg }
    }

    async fn connection(&self) -> Result<Connection> {
        // 250ms upper bound – don't let redis I/O block the async runtime.
        timeout(Duration::from_millis(250), self.pool.get())
            .await
            .map_err(|_| CacheError::Timeout(Duration::from_millis(250)))?
            .map_err(CacheError::from)
    }
}

#[async_trait]
impl ResponseCache for RedisResponseCache {
    async fn try_get<T>(&self, key: &CacheKey) -> Result<Option<CachedEnvelope<T>>>
    where
        T: DeserializeOwned + Send,
    {
        let redis_key = key.to_redis_key(&self.cfg);
        let mut conn = self.connection().await?;
        let raw: Option<Vec<u8>> = conn.get(redis_key).await?;

        if let Some(bin) = raw {
            let envelope: CachedEnvelope<T> = serde_json::from_slice(&bin)?;
            if envelope.is_fresh(&self.cfg) {
                if self.cfg.verbose {
                    tracing::debug!("cache hit: {}", key.to_redis_key(&self.cfg));
                }
                return Ok(Some(envelope));
            }

            // Stale – allow if within grace period.
            let age_ms = SystemTime::now()
                .duration_since(SystemTime::UNIX_EPOCH)
                .unwrap()
                .as_millis() as u64
                - envelope.created_at;
            if age_ms <= (self.cfg.ttl + self.cfg.stale_while_revalidate).as_millis() as u64 {
                if self.cfg.verbose {
                    tracing::debug!("serving stale cache entry for {}", key.to_redis_key(&self.cfg));
                }
                // Kick off async revalidation but don't await.
                let key_clone = key.clone();
                let this = self.clone();
                tokio::spawn(async move {
                    if let Err(e) = this.invalidate(&key_clone).await {
                        tracing::error!("failed to invalidate stale cache key: {:?}", e);
                    }
                });
                Ok(Some(envelope))
            } else {
                // Too old – treat as miss.
                Ok(None)
            }
        } else {
            if self.cfg.verbose {
                tracing::trace!("cache miss: {}", key.to_redis_key(&self.cfg));
            }
            Ok(None)
        }
    }

    async fn store<T>(&self, key: &CacheKey, value: &T) -> Result<()>
    where
        T: Serialize + Send + Sync,
    {
        let envelope = CachedEnvelope::new(value)?;
        let redis_key = key.to_redis_key(&self.cfg);
        let mut conn = self.connection().await?;
        let bin = serde_json::to_vec(&envelope)?;
        conn.set_ex::<_, _, ()>(
            redis_key,
            bin,
            self.cfg
                .ttl
                .as_secs()
                .try_into()
                .expect("ttl won't exceed i32::MAX"),
        )
        .await?;
        if self.cfg.verbose {
            tracing::debug!("cache store: {}", key.to_redis_key(&self.cfg));
        }
        Ok(())
    }

    async fn invalidate(&self, key: &CacheKey) -> Result<()> {
        let redis_key = key.to_redis_key(&self.cfg);
        let mut conn = self.connection().await?;
        let _: () = conn.del(redis_key).await?;
        if self.cfg.verbose {
            tracing::info!("cache invalidated: {}", key.to_redis_key(&self.cfg));
        }
        Ok(())
    }
}

impl Clone for RedisResponseCache {
    fn clone(&self) -> Self {
        Self {
            pool: self.pool.clone(),
            cfg: self.cfg.clone(),
        }
    }
}

//
// ---------------------- HTTP Helper (optional) ---------------------------
//
impl RedisResponseCache {
    /// Convenience helper that wires the caching layer into an `axum` handler.
    /// Only enabled if `axum` feature is declared in `Cargo.toml`.
    #[cfg(feature = "axum")]
    pub async fn with_cache<B, T, F, Fut>(
        &self,
        req: Request<B>,
        tenant_id: &str,
        api_version: u16,
        compute: F,
    ) -> std::result::Result<axum::response::Response, axum::BoxError>
    where
        B: Send + 'static,
        T: Serialize + DeserializeOwned + Send + 'static,
        F: FnOnce() -> Fut + Send,
        Fut: std::future::Future<Output = std::result::Result<(StatusCode, T), axum::BoxError>>
            + Send,
    {
        let key = CacheKey::from_request(&req, tenant_id, api_version);
        let headers = req.headers();

        // Check for explicit no-cache directive.
        let bypass = headers
            .get(header::CACHE_CONTROL)
            .map(|v| v.to_str().unwrap_or_default().contains("no-cache"))
            .unwrap_or(false);

        if !bypass {
            if let Some(env) = self.try_get::<T>(&key).await.map_err(|e| {
                tracing::error!("cache get error: {e:?}");
                axum::BoxError::from(e)
            })? {
                let mut resp = axum::Json(env.payload).into_response();
                resp.headers_mut()
                    .insert(header::ETAG, env.etag.parse().unwrap());
                resp.headers_mut().insert(
                    header::CACHE_CONTROL,
                    format!("max-age={}", self.cfg.ttl.as_secs())
                        .parse()
                        .unwrap(),
                );
                return Ok(resp);
            }
        }

        // Miss or bypass -> compute and store.
        let (status, body) = compute().await?;
        self.store(&key, &body).await.map_err(|e| {
            tracing::error!("cache store error: {e:?}");
            axum::BoxError::from(e)
        })?;
        let mut resp = (status, axum::Json(body)).into_response();
        resp.headers_mut()
            .insert(header::CACHE_CONTROL, "max-age=0".parse().unwrap());
        Ok(resp)
    }
}
```
# 001 â€“ Adopt a Modular-Monolith Architecture  
Status: Accepted  
Date: 2024-06-08  
Deciders: Core Architecture Working Group (CAWG)  
Supersedes: *n/a*  
Tags: [`architecture`](#), [`modular-monolith`](#), [`csharp`](#), [`mlops`](#)

---

## 1. Context  

CanvasCraft ML Studio is an end-to-end **MVC-driven MLOps platform** that targets creative professionals iterating on generative media.  
While the business road-map forecasts multiple deployment targets (desktop, on-prem, cloud, edge), the immediate product goals are:

* Rapid iteration on **feature-engineering palettes** and **hyper-parameter color-wheels**.  
* Tight coupling between **experiment-tracking**, **feature store**, and **model registry** to guarantee lineage.  
* A **reactive model-monitoring** feedback loop that must not fall out of sync with training pipelines.  
* A single deployable artifact that remains **operationally simple** yet **modular enough** to allow multiple teams (Data Science, UX, DevOps) to collaborate in parallel.

The team evaluated the following architectural styles:

| Candidate | Pros | Cons |
|-----------|------|------|
| Pure Micro-services | Independent deployability; granular scaling | YAGNI for current size; high operational overhead; transaction boundaries complicate ACID model registry |
| **Modular Monolith (Internal Hexagons)** | Clear module boundaries; performant in-process calls; single deployment unit | Requires discipline to avoid â€œbig ball of mudâ€; limited horizontal scaling |
| Packaged Plugins (OSGi style) | Hot-swappable â€œbrushâ€ plugins; strict contracts | Added complexity to load/unload modules; less tooling in .NET ecosystem |
| Serverless Functions | Zero-management infra; pay-per-use for burst training jobs | Cold-start latency for interactive â€œgalleryâ€ UI; cross-function state management painful |

Given current **team size**, the **need for synchronous cross-module transactions** (e.g., dataset â†” feature store â†” model registry), and the **desire to postpone DevOps overhead** until usage patterns stabilize, we choose the **Modular Monolith**.

---

## 2. Decision  

We will build CanvasCraft ML Studio as a **C# 8/9, .NET 8** modular monolith with the following rules:

1. **Single Deployment Unit**  
   A single Docker container / process hosts all modules (Train, Serve, Monitor, UX, etc.).
2. **Explicit Module Boundaries**  
   Modules are organized under `/src/{BoundedContext}.{Module}` namespaces, compiled into **separate class libraries** referenced by a thin *Composition Root* (Web / gRPC Host).
3. **Internal Hexagonal Architecture** per module  
   Each module exposes its own:
   * `Application` layer (Use-Cases, CQRS commands/queries)  
   * `Domain` layer (Aggregates, Value Objects, Domain Events)  
   * `Infrastructure` layer (EF Core, Redis, Kafka, TensorRT, etc.)
4. **Public Contracts** *(C# interfaces + OpenAPI)*  
   Modules interact only via their `*.Contracts` assemblies to prevent direct reference leaks.
5. **Shared Kernel** kept minimal  
   Only cross-cutting primitives (e.g., `Result<T>`, `IEvent`, `IDomainNotification`) live here.
6. **Dependency Inversion through Internal DI Container**  
   All external dependencies are injected via `IServiceCollection` extensions located in each moduleâ€™s `Infrastructure` layer.

---

## 3. Consequences  

### Positive  

* ğŸš€ **Velocity** â€“ Teams commit to their modules without touching others; compile-time boundaries give rapid feedback.  
* ğŸ”¬ **Observability** â€“ Since calls are in-process, **OpenTelemetry** tracing is cheap; back-pressure can be simulated with Polly policies.  
* ğŸ—ƒï¸ **Transactional Integrity** â€“ The feature store and model registry execute in the same ACID transaction when needed (e.g., using EF Core `IDbContextTransaction`).  
* ğŸ› ï¸ **Gradual Extraction Path** â€“ If a moduleâ€™s load pattern grows, we can extract it into a micro-service by lifting its contract and infrastructure *without* rewriting domain code.

### Negative / Risks  

* ğŸ—ï¸ **Discipline Required** â€“ Nothing (besides CI linting) prevents developers from taking a rogue reference into another moduleâ€™s `Infrastructure` assembly.  
* ğŸ“ˆ **Limited Horizontal Scaling** â€“ The entire monolith scales as one unit. Mitigation: run multiple container replicas behind a load balancer.  
* ğŸ’¼ **Deployment Blast Radius** â€“ A change in any module triggers a full redeploy. Our blue-green pipeline must be robust.

---

## 4. Implementation Sketch  

### 4.1. Directory / Namespace Layout  

```
CanvasCraftMLStudio/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ SharedKernel/
â”‚   â”‚   â””â”€â”€ CanvasCraft.SharedKernel.csproj
â”‚   â”œâ”€â”€ ExperimentTracking/
â”‚   â”‚   â”œâ”€â”€ Contracts/
â”‚   â”‚   â”œâ”€â”€ Domain/
â”‚   â”‚   â”œâ”€â”€ Application/
â”‚   â”‚   â””â”€â”€ Infrastructure/
â”‚   â”œâ”€â”€ FeatureEngineering/
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ ModelRegistry/
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”œâ”€â”€ ServingGallery/
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ WebHost/
â”‚       â””â”€â”€ CanvasCraft.WebHost.csproj
â””â”€â”€ docs/
    â””â”€â”€ architecture/
        â””â”€â”€ adr/
            â””â”€â”€ ...
```

### 4.2. Composition Root (simplified)

```csharp
// CanvasCraft.WebHost/Program.cs
using CanvasCraft.SharedKernel;
using CanvasCraft.ExperimentTracking.Infrastructure;
using CanvasCraft.FeatureEngineering.Infrastructure;
using CanvasCraft.ModelRegistry.Infrastructure;
using CanvasCraft.ServingGallery.Infrastructure;

var builder = WebApplication.CreateBuilder(args);
builder.Services
    .AddSharedKernel()
    .AddExperimentTrackingModule(builder.Configuration)
    .AddFeatureEngineeringModule(builder.Configuration)
    .AddModelRegistryModule(builder.Configuration)
    .AddServingGalleryModule(builder.Configuration);

builder.Services.AddControllers().AddNewtonsoftJson();

var app = builder.Build();
app.MapControllers();
app.Run();
```

### 4.3. Enforcing Boundaries via Roslyn Analyzer

A custom Roslyn analyzer (loaded in `Directory.Build.props`) blocks forbidden references:

```csharp
[DiagnosticAnalyzer(LanguageNames.CSharp)]
public sealed class NoInfrastructureLeakAnalyzer : DiagnosticAnalyzer
{
    private static readonly DiagnosticDescriptor Rule = new(
        id: "CCMS001",
        title: "No cross-module Infrastructure references",
        messageFormat: "Project '{0}' should not reference '{1}.Infrastructure'",
        category: "Architecture",
        defaultSeverity: DiagnosticSeverity.Error,
        isEnabledByDefault: true);

    public override ImmutableArray<DiagnosticDescriptor> SupportedDiagnostics => ImmutableArray.Create(Rule);

    public override void Initialize(AnalysisContext context) =>
        context.RegisterCompilationStartAction(start =>
        {
            var infraProjects = start.Compilation.ReferencedAssemblyNames
                .Where(a => a.Name.EndsWith(".Infrastructure", StringComparison.Ordinal))
                .ToHashSet(StringComparer.Ordinal);

            start.RegisterSymbolAction(symbolContext =>
            {
                var assembly = symbolContext.Symbol.ContainingAssembly?.Name;
                if (assembly is null || !assembly.EndsWith(".Infrastructure"))
                {
                    foreach (var infra in infraProjects)
                    {
                        if (symbolContext.Compilation.AssemblyName == infra.ToString())
                            continue;

                        symbolContext.ReportDiagnostic(
                            Diagnostic.Create(Rule, Location.None, assembly, infra));
                    }
                }
            }, SymbolKind.NamedType);
        });
}
```

---

## 5. Alternatives Considered  

1. **Full Micro-Services** with gRPC & Kafka  
   *Rejected* â€“ Over-engineering at current scale; slows feature velocity.  
2. **Serverless-First** using Azure Functions & Durable Orchestration  
   *Rejected* â€“ Real-time â€œgalleryâ€ UI would suffer cold starts; local dev experience poor.  
3. **Plugin-Oriented (MEF) Desktop App**  
   *Rejected* â€“ Conflicts with requirement for cloud-native CI/CD and containerization.

---

## 6. Validation Plan  

* Implement two pilot modules (**ExperimentTracking** and **FeatureEngineering**) under this architecture.  
* Run performance benchmark: ingest â†’ transform â†’ model fit; target < 250 ms overhead vs. baseline script.  
* Conduct *â€œdesign spikeâ€* to extract ExperimentTracking into a micro-service after initial release and measure required refactor effort (< 8 story points target).  
* Audit module boundaries via the Roslyn analyzer in every PR.

---

## 7. References  

* â€œMonolith Firstâ€ â€“ Martin Fowler, 2015  
* â€œA Modular Monolith Architecture in .NETâ€ â€“ Khorikov, 2023  
* OpenTelemetry .NET Instrumentation Guidelines, v1.7  
* Domain-Driven Design Tackling Complexity in the Heart of Software â€“ Evans, 2004  

---

*This document is living; amendments require a new ADR.*
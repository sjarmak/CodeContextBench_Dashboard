```python
"""
tests.unit.services.networking.test_connection_handler
======================================================

Unit‐tests for the server-side WebSocket connection handler that backs the
LedgerQuest Engine’s real-time networking capabilities.  The handler is
implemented as an AWS Lambda function that is triggered by API-Gateway
WebSocket “$connect” and “$disconnect” routes.  Its responsibilities include
persisting active connections to DynamoDB so that gameplay events can later be
fan-out to the correct clients in an entirely serverless fashion.

The test-suite below validates the following high-level behaviours:

* Successful connection events are persisted and acknowledged.
* Duplicate connectionIds are handled idempotently.
* Input validation failures are surfaced with 4xx responses.
* Disconnect events clean up state regardless of whether the connection was
  ever recorded (defensive programming against at-least-once delivery).
"""

from __future__ import annotations

import json
import os
import uuid
from importlib import reload
from types import SimpleNamespace
from typing import Any, Dict

import boto3
import pytest
from moto import mock_dynamodb2
from mypy_boto3_dynamodb.service_resource import Table  # type: ignore[import]


# --------------------------------------------------------------------------- #
# Helper utilities                                                            #
# --------------------------------------------------------------------------- #
def _build_connect_event(
    *,
    connection_id: str | None = None,
    stage: str = "test",
    tenant_id: str = "tenant-001",
) -> Dict[str, Any]:
    """
    Create a fake API-Gateway “$connect” event.

    Parameters
    ----------
    connection_id:
        Overrides the random connectionId normally generated by API-Gateway.
    stage:
        Which WebSocket stage the request is coming from (dev, prod, etc.).
    tenant_id:
        Multi-tenant business identifier carried in the query-string.

    Returns
    -------
    dict
        A realistic Lambda proxy event payload.
    """
    return {
        "requestContext": {
            "connectionId": connection_id or str(uuid.uuid4()),
            "stage": stage,
            # Additional metadata that the handler might rely on.
            "domainName": "example.com",
            "apiId": "abc123",
            "eventType": "CONNECT",
            "routeKey": "$connect",
        },
        "queryStringParameters": {"tenantId": tenant_id},
        "headers": {
            "Host": "example.com",
        },
        "isBase64Encoded": False,
        "body": None,
    }


def _build_disconnect_event(
    *, connection_id: str, stage: str = "test"
) -> Dict[str, Any]:
    """Create a fake API-Gateway “$disconnect” event."""
    return {
        "requestContext": {
            "connectionId": connection_id,
            "stage": stage,
            "domainName": "example.com",
            "apiId": "abc123",
            "eventType": "DISCONNECT",
            "routeKey": "$disconnect",
        },
        "isBase64Encoded": False,
        "body": None,
    }


class _LambdaContextStub(SimpleNamespace):
    """
    Extremely light-weight emulator for the boto3 LambdaContext object.

    Only the attributes that production code *might* access are provided.
    """

    function_name: str = "connection-handler"
    memory_limit_in_mb: int = 256
    aws_request_id: str = "unit-test"


# --------------------------------------------------------------------------- #
# PyTest fixtures                                                             #
# --------------------------------------------------------------------------- #
@pytest.fixture(scope="function")
def dynamodb_table(monkeypatch) -> Table:
    """
    Spins up a fully-isolated, in-memory DynamoDB table via Moto.

    Environment variables consumed by production code are injected so that the
    module under test can resolve the table at import-time.
    """
    with mock_dynamodb2():
        table_name = "LQ_Connections"
        monkeypatch.setenv("CONNECTIONS_TABLE_NAME", table_name)

        resource = boto3.resource("dynamodb", region_name="us-east-1")
        table = resource.create_table(
            TableName=table_name,
            KeySchema=[{"AttributeName": "connectionId", "KeyType": "HASH"}],
            AttributeDefinitions=[{"AttributeName": "connectionId", "AttributeType": "S"}],
            BillingMode="PAY_PER_REQUEST",
        )
        table.wait_until_exists()

        yield table


@pytest.fixture(scope="function")
def handler_module(dynamodb_table, monkeypatch):
    """
    Import (or reload) the target handler *after* the Moto table & env-vars
    exist; this guarantees boto3 has been patched and the table can be
    discovered on module initialisation.
    """
    # Local import to avoid polluting global namespace during collection time.
    from ledgerquest.services.networking import connection_handler as _module

    # Ensure fresh state each test — connection handler caches the table.
    module = reload(_module)

    # Verify that the handler points to the mocked DynamoDB table.
    assert module._CONNECTIONS_TABLE.name == dynamodb_table.name
    return module


# --------------------------------------------------------------------------- #
# Test-cases                                                                  #
# --------------------------------------------------------------------------- #
def test_handle_connect_success(handler_module, dynamodb_table):
    """A well-formed `$connect` event results in a persisted record."""
    event = _build_connect_event()
    ctx = _LambdaContextStub()

    result = handler_module.handle_connect(event, ctx)

    assert result == {"statusCode": 200, "body": json.dumps({"ok": True})}

    # The item must have been written to the database.
    stored = dynamodb_table.get_item(Key={"connectionId": event["requestContext"]["connectionId"]})
    assert "Item" in stored
    assert stored["Item"]["tenantId"] == event["queryStringParameters"]["tenantId"]


def test_handle_connect_idempotent_on_duplicates(handler_module, dynamodb_table):
    """
    Re-invoking the connect handler with the same connectionId should be
    idempotent — no duplicate rows and no 5xx errors.
    """
    event = _build_connect_event()
    ctx = _LambdaContextStub()

    # First connection attempt.
    response_1 = handler_module.handle_connect(event, ctx)
    assert response_1["statusCode"] == 200

    # Second connection attempt with the identical connectionId.
    response_2 = handler_module.handle_connect(event, ctx)
    assert response_2["statusCode"] in (200, 409)  # Either OK or conflict.

    # Table must still have exactly one record.
    assert dynamodb_table.item_count == 1


@pytest.mark.parametrize(
    "broken_event, expected_status",
    [
        ({}, 400),  # Completely malformed.
        (_build_connect_event(connection_id=None), 400),  # Missing connectionId.
    ],
)
def test_handle_connect_validation_failures(handler_module, broken_event, expected_status):
    """Input validation errors surface as client errors (4xx)."""
    ctx = _LambdaContextStub()
    response = handler_module.handle_connect(broken_event, ctx)
    assert response["statusCode"] == expected_status
    assert "error" in json.loads(response["body"])


def test_handle_disconnect_success(handler_module, dynamodb_table):
    """An existing record is removed and ACK-ed with HTTP 200."""
    connect_event = _build_connect_event()
    ctx = _LambdaContextStub()

    # Seed the record.
    handler_module.handle_connect(connect_event, ctx)
    assert dynamodb_table.item_count == 1

    # Now disconnect.
    disc_event = _build_disconnect_event(
        connection_id=connect_event["requestContext"]["connectionId"]
    )
    response = handler_module.handle_disconnect(disc_event, ctx)

    assert response == {"statusCode": 200, "body": json.dumps({"ok": True})}
    assert dynamodb_table.item_count == 0


def test_handle_disconnect_graceful_if_record_missing(handler_module):
    """
    Disconnecting a connectionId that isn't in the table should *not* raise —
    this can happen when `$disconnect` is delivered out of order.
    """
    disc_event = _build_disconnect_event(connection_id=str(uuid.uuid4()))
    ctx = _LambdaContextStub()

    response = handler_module.handle_disconnect(disc_event, ctx)

    assert response["statusCode"] == 200
    # Body should still be a JSON encoded structure.
    assert json.loads(response["body"]) == {"ok": True}
```
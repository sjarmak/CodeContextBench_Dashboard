```rust
//! src/module_50.rs
//!
//! Real-time analysis engine for ChirpPulse.
//!
//! This module demonstrates how the platform can consume a high-volume
//! Kafka stream, apply a hot-swappable sentiment‐analysis strategy, push
//! the result to an outbound topic, and expose Prometheus metrics—all
//! without interrupting traffic.
//
//  NOTE: Compiles with the following dependencies in Cargo.toml:
//
//  [dependencies]
//  anyhow        = "1"
//  async-trait   = "0.1"
//  futures       = "0.3"
//  once_cell     = "1"
//  prometheus    = "0.13"
//  rdkafka       = { version = "0.34", features = ["tokio"] }
//  serde         = { version = "1", features = ["derive"] }
//  serde_json    = "1"
//  tokio         = { version = "1", features = ["macros", "rt-multi-thread", "time", "sync", "net"] }
//  tracing       = "0.1"
//  tracing-subscriber = { version = "0.3", features = ["env-filter"] }
//  warp          = "0.3"

use std::{
    collections::HashSet,
    future::Future,
    sync::Arc,
    time::{Duration, Instant},
};

use anyhow::{Context, Result};
use async_trait::async_trait;
use futures::StreamExt;
use once_cell::sync::Lazy;
use prometheus::{
    opts, Encoder, IntCounter, IntGauge, Registry, TextEncoder,
};
use rdkafka::{
    consumer::{CommitMode, Consumer, StreamConsumer},
    message::BorrowedMessage,
    producer::{FutureProducer, FutureRecord},
    ClientConfig,
};
use serde::{Deserialize, Serialize};
use tokio::{
    select,
    sync::{watch, RwLock},
    task,
    time,
};
use tracing::{error, info, instrument};

/// Kafka constants
const SOURCE_TOPIC: &str = "chirppulse.enriched";
const SINK_TOPIC: &str = "chirppulse.analysis";
const GROUP_ID: &str = "chirppulse-realtime-analysis";

/// Public social chatter event after enrichment but before analysis.
#[derive(Debug, Clone, Deserialize)]
struct EnrichedEvent {
    id: String,
    user_id: String,
    text: String,
    lang: String,
    timestamp: u64,
    #[serde(default)]
    hashtags: Vec<String>,
}

/// Analysis result we publish downstream.
#[derive(Debug, Clone, Serialize)]
struct AnalysisEvent {
    id: String,
    sentiment_score: f32,
    strategy_version: String,
    processed_at: u64,
}

/// Trait defining analysis strategy.
#[async_trait]
pub trait AnalysisStrategy: Send + Sync {
    /// Identifies the version of the algorithm. Useful for governance.
    fn version(&self) -> &str;

    /// Run analysis on an event, producing a score in the range [-1, 1].
    async fn analyze(&self, event: &EnrichedEvent) -> f32;
}

/// A very naive lexicon-based sentiment algorithm.
/// Counts positive / negative tokens from two static sets.
pub struct LexiconStrategy {
    positive: HashSet<&'static str>,
    negative: HashSet<&'static str>,
}
impl Default for LexiconStrategy {
    fn default() -> Self {
        static POSITIVE_WORDS: &[&str] = &[
            "good", "great", "awesome", "happy", "love", "excellent", "nice",
        ];
        static NEGATIVE_WORDS: &[&str] = &[
            "bad", "terrible", "awful", "sad", "hate", "poor", "angry",
        ];
        Self {
            positive: POSITIVE_WORDS.iter().copied().collect(),
            negative: NEGATIVE_WORDS.iter().copied().collect(),
        }
    }
}
#[async_trait]
impl AnalysisStrategy for LexiconStrategy {
    fn version(&self) -> &str {
        "lexicon-v1"
    }

    async fn analyze(&self, event: &EnrichedEvent) -> f32 {
        let tokens = event.text.split_ascii_whitespace().map(|s| s.to_lowercase());
        let mut score = 0i32;

        for token in tokens {
            if self.positive.contains(token.as_str()) {
                score += 1;
            } else if self.negative.contains(token.as_str()) {
                score -= 1;
            }
        }

        // Normalize to [-1, 1]
        (score as f32) / 10.0
    }
}

/// Example of a more advanced strategy.
/// Pretends to call an external ML model via gRPC (simulated w/ sleep).
pub struct ExternalModelStrategy;
#[async_trait]
impl AnalysisStrategy for ExternalModelStrategy {
    fn version(&self) -> &str {
        "ml-bert-v2.3"
    }

    async fn analyze(&self, event: &EnrichedEvent) -> f32 {
        // Simulate network latency
        time::sleep(Duration::from_millis(15)).await;
        // For demo, derive pseudo-random deterministic score based on id hash
        let hash = seahash::hash(event.id.as_bytes());
        let value = (hash % 200) as f32 / 100.0 - 1.0; // [-1, 1]
        value
    }
}

/// Manager that can hot-swap the current strategy at runtime.
#[derive(Clone)]
pub struct StrategyManager {
    inner: Arc<RwLock<Box<dyn AnalysisStrategy>>>,
    notifier: watch::Sender<String>,
}

impl StrategyManager {
    pub fn new<S: AnalysisStrategy + 'static>(strategy: S) -> Self {
        let (tx, _rx) = watch::channel(strategy.version().to_owned());
        Self {
            inner: Arc::new(RwLock::new(Box::new(strategy))),
            notifier: tx,
        }
    }

    /// Returns receiver that is triggered whenever the strategy changes.
    pub fn subscribe(&self) -> watch::Receiver<String> {
        self.notifier.subscribe()
    }

    /// Replace the existing strategy with the new one.
    pub async fn swap<S: AnalysisStrategy + 'static>(&self, strategy: S) {
        {
            let mut guard = self.inner.write().await;
            *guard = Box::new(strategy);
        }
        // Notify subscribers
        let _ = self.notifier.send(self.current_version().to_owned());
        info!("Strategy swapped. Now running {}", self.current_version());
    }

    pub async fn analyze(&self, evt: &EnrichedEvent) -> f32 {
        let guard = self.inner.read().await;
        guard.analyze(evt).await
    }

    pub fn current_version(&self) -> &str {
        // read lock not needed for version string
        let guard = self.inner.blocking_read();
        guard.version()
    }
}

/// Metrics wrapper
struct Metrics {
    inbound_msgs: IntCounter,
    outbound_msgs: IntCounter,
    processing_lag_ms: IntGauge,
    registry: Registry,
}

impl Metrics {
    fn new() -> Self {
        let registry = Registry::new();
        let inbound_msgs =
            IntCounter::with_opts(opts!("inbound_msgs_total", "Inbound kafka messages")).unwrap();
        let outbound_msgs =
            IntCounter::with_opts(opts!("outbound_msgs_total", "Outbound kafka messages")).unwrap();
        let processing_lag_ms =
            IntGauge::with_opts(opts!("processing_lag_ms", "Time between event and processing"))
                .unwrap();

        registry.register(Box::new(inbound_msgs.clone())).unwrap();
        registry.register(Box::new(outbound_msgs.clone())).unwrap();
        registry.register(Box::new(processing_lag_ms.clone())).unwrap();

        Self {
            inbound_msgs,
            outbound_msgs,
            processing_lag_ms,
            registry,
        }
    }

    fn render(&self) -> Result<String> {
        let encoder = TextEncoder::new();
        let metric_families = self.registry.gather();
        let mut buf = Vec::new();
        encoder.encode(&metric_families, &mut buf)?;
        Ok(String::from_utf8(buf)?)
    }
}

/// Engine that wires together Kafka IO, strategy execution, and metrics.
pub struct RealTimeEngine {
    consumer: StreamConsumer,
    producer: FutureProducer,
    strategy_mgr: StrategyManager,
    metrics: Metrics,
}

impl RealTimeEngine {
    /// Create engine with default kafka configuration.
    pub fn new(strategy_mgr: StrategyManager) -> Result<Self> {
        // Kafka consumer
        let consumer: StreamConsumer = ClientConfig::new()
            .set("group.id", GROUP_ID)
            .set("bootstrap.servers", "localhost:9092")
            .set("enable.auto.commit", "false")
            .set("auto.offset.reset", "latest")
            .create()
            .context("Failed to create consumer")?;

        consumer
            .subscribe(&[SOURCE_TOPIC])
            .context("Can't subscribe to source topic")?;

        // Kafka producer
        let producer: FutureProducer = ClientConfig::new()
            .set("bootstrap.servers", "localhost:9092")
            .create()
            .context("Failed to create producer")?;

        Ok(Self {
            consumer,
            producer,
            strategy_mgr,
            metrics: Metrics::new(),
        })
    }

    /// Start the main processing loop.
    #[instrument(skip(self))]
    pub async fn run(mut self) -> Result<()> {
        // Spawn metrics HTTP endpoint
        let metrics = self.metrics.registry.clone();
        task::spawn(async move {
            Self::serve_metrics(metrics).await;
        });

        info!("Real-time engine started.");
        while let Some(message) = self.consumer.stream().next().await {
            match message {
                Err(err) => error!("Kafka error: {}", err),
                Ok(msg) => {
                    if let Err(err) = self.handle_message(&msg).await {
                        error!("Error processing message: {:?}", err);
                    }
                    // commit offset regardless to avoid reprocessing poison pill
                    if let Err(e) = self.consumer.commit_message(&msg, CommitMode::Async) {
                        error!("Commit failed: {:?}", e);
                    }
                }
            }
        }
        Ok(())
    }

    /// Handle a single kafka message.
    async fn handle_message(&self, msg: &BorrowedMessage<'_>) -> Result<()> {
        self.metrics.inbound_msgs.inc();

        let payload = msg.payload().context("Empty payload")?;
        let enriched: EnrichedEvent = serde_json::from_slice(payload)?;

        // Calculate lag (ms)
        let sent_ts = enriched.timestamp;
        let now_ms = time::Instant::now(); // not epoch but diff; let's approximate with unix time
        let lag = (time::SystemTime::now()
            .duration_since(std::time::UNIX_EPOCH)?
            .as_millis() as u64)
            .saturating_sub(sent_ts);
        self.metrics.processing_lag_ms.set(lag as i64);

        // Run analysis
        let score = self.strategy_mgr.analyze(&enriched).await;
        let analysis = AnalysisEvent {
            id: enriched.id.clone(),
            sentiment_score: score,
            strategy_version: self.strategy_mgr.current_version().to_owned(),
            processed_at: (time::SystemTime::now()
                .duration_since(std::time::UNIX_EPOCH)?
                .as_millis()) as u64,
        };

        // Produce to sink topic
        let payload = serde_json::to_vec(&analysis)?;
        self.producer
            .send(
                FutureRecord::to(SINK_TOPIC)
                    .key(&analysis.id)
                    .payload(&payload),
                Duration::from_secs(0),
            )
            .await
            .map_err(|(e, _)| anyhow::anyhow!("Failed to produce: {:?}", e))?;

        self.metrics.outbound_msgs.inc();
        Ok(())
    }

    /// Expose `/metrics` over HTTP for Prometheus.
    async fn serve_metrics(registry: Registry) {
        let metrics_route = warp::path!("metrics").map(move || {
            let encoder = TextEncoder::new();
            let metric_families = registry.gather();
            let mut buf = Vec::new();
            if encoder.encode(&metric_families, &mut buf).is_ok() {
                warp::http::Response::builder()
                    .header("Content-Type", encoder.format_type())
                    .body(buf)
            } else {
                warp::http::Response::builder()
                    .status(500)
                    .body(Vec::<u8>::new())
            }
        });
        info!("Serving /metrics on 0.0.0.0:9898");
        warp::serve(metrics_route)
            .run(([0, 0, 0, 0], 9898))
            .await;
    }
}

/// Demonstration of hot-swapping strategies at runtime.
///
/// In real deployment, this would be triggered by an admin API or
/// configuration flag.
async fn demo_strategy_swapper(mgr: StrategyManager) {
    let mut interval = time::interval(Duration::from_secs(30));
    loop {
        interval.tick().await;
        info!("Swapping strategy to ExternalModelStrategy");
        mgr.swap(ExternalModelStrategy).await;

        interval.tick().await;
        info!("Swapping strategy back to LexiconStrategy");
        mgr.swap(LexiconStrategy::default()).await;
    }
}

/// Entrypoint for standalone binary.
/// The file lives under `src/` so it can be either library or bin.
/// Enable `[[bin]]` target in Cargo.toml to compile as executable.
#[tokio::main(flavor = "multi_thread")]
async fn main() -> Result<()> {
    // Initialize logging
    tracing_subscriber::fmt()
        .with_env_filter("info")
        .init();

    let strategy_mgr = StrategyManager::new(LexiconStrategy::default());
    let engine = RealTimeEngine::new(strategy_mgr.clone())?;

    // Spawn strategy swapper demo in background
    tokio::spawn(demo_strategy_swapper(strategy_mgr));

    engine.run().await
}
```
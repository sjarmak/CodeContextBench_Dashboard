```rust
//! src/module_82.rs
//!
//! Out-box-pattern implementation for domain events that underpin the
//! EduPulse Live social-learning hub.  This module is responsible for
//! 1.  Persisting domain events atomically in the same Postgres transaction
//!     that mutates the aggregate (via `EventStore`).
//! 2.  Dispatching those events *exactly-once* to an AMQP message broker
//!     (RabbitMQ) via the `BrokerDispatcher`.
//!
//! The code is production-grade: cancel-safe, fully async, provider-agnostic
//! (swap AMQP for Kafka by changing a single adapter), and observable
//! through [`tracing`] spans.
//
//  ==============  Crate Features & Dependencies  ==============
//
//  tokio      -- asynchronous runtime
//  sqlx       -- async Postgres driver/ORM (with "runtime-tokio", "postgres")
//  lapin      -- AMQP 0-9-1 (RabbitMQ) client ("executor", "runtime_tokio")
//  chrono     -- strongly-typed timestamps
//  serde      -- (de)serialization to JSON
//  thiserror  -- ergonomic error enumeration
//  tracing    -- structured logging
//

use std::time::Duration;

use chrono::{DateTime, Utc};
use lapin::{
    options::{BasicPublishOptions, QueueDeclareOptions},
    publisher_confirm::Confirmation,
    BasicProperties, Channel, Connection, ConnectionProperties,
};
use serde::{Deserialize, Serialize};
use sqlx::{postgres::PgQueryAs, PgPool, Postgres, QueryBuilder, Row, Transaction};
use thiserror::Error;
use tokio::time;
use tracing::{debug, error, info, instrument, warn};
use uuid::Uuid;

/// Identifier for aggregates (e.g., a `LearningPulse` or `Submission`).
pub type AggregateId = Uuid;

/// Strongly-typed event identifier (UUID v4).
pub type EventId = Uuid;

/// The *name* of an event, e.g., `learning_pulse.created`.
pub type EventType = String;

/// Transport-agnostic event envelope.  `payload` is an arbitrary JSON blob.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct EventEnvelope {
    pub event_id: EventId,
    pub aggregate_id: AggregateId,
    pub event_type: EventType,
    pub payload: serde_json::Value,
    #[serde(with = "chrono::serde::ts_seconds")]
    pub occurred_at: DateTime<Utc>,
}

/// Helper trait implemented by every domain event.
///
/// Implementors should be `Serialize` so that we can automatically
/// transcode them to JSON.
pub trait DomainEvent: Serialize {
    /// Fully-qualified name for the event, used by subscribers for routing.
    const EVENT_TYPE: &'static str;

    /// Get the `aggregate_id` to which this event belongs.
    fn aggregate_id(&self) -> AggregateId;

    /// Convert to a generic envelope for storage/dispatch.
    fn into_envelope(self) -> EventEnvelope
    where
        Self: Sized,
    {
        EventEnvelope {
            event_id: Uuid::new_v4(),
            aggregate_id: self.aggregate_id(),
            event_type: Self::EVENT_TYPE.to_owned(),
            payload: serde_json::to_value(self).expect("DomainEvent is always serializable"),
            occurred_at: Utc::now(),
        }
    }
}

/* ============================================================================
   Example Domain Events
   ========================================================================== */

/// A teacher created a new learning pulse.
#[derive(Debug, Serialize)]
pub struct LearningPulseCreated {
    pub pulse_id: AggregateId,
    pub author_id: Uuid,
    pub title: String,
}

impl DomainEvent for LearningPulseCreated {
    const EVENT_TYPE: &'static str = "learning_pulse.created";

    fn aggregate_id(&self) -> AggregateId {
        self.pulse_id
    }
}

/// A student submitted an answer to a pulse.
#[derive(Debug, Serialize)]
pub struct SubmissionReceived {
    pub submission_id: AggregateId,
    pub pulse_id: AggregateId,
    pub student_id: Uuid,
}

impl DomainEvent for SubmissionReceived {
    const EVENT_TYPE: &'static str = "submission.received";

    fn aggregate_id(&self) -> AggregateId {
        self.submission_id
    }
}

/* ============================================================================
   Persistence Layer (Outbox Table)
   ========================================================================== */

/// Tableâ€schema-agnostic event store.  Uses an *append-only* table
/// `event_outbox(id, aggregate_id, event_type, payload, occurred_at, dispatched_at)`.
pub struct EventStore {
    pool: PgPool,
}

impl EventStore {
    pub fn new(pool: PgPool) -> Self {
        Self { pool }
    }

    /// Persist a batch of domain events **inside an existing transaction** so
    /// that writes are atomic with the aggregate mutation.
    ///
    /// Recommended usage:
    /// ```ignore
    /// let mut tx = pool.begin().await?;
    /// // mutate aggregate tables...
    /// event_store.append(&mut tx, events).await?;
    /// tx.commit().await?;
    /// ```
    #[instrument(skip_all, fields(batch_size = events.len()))]
    pub async fn append<'t>(
        &self,
        tx: &mut Transaction<'t, Postgres>,
        events: impl IntoIterator<Item = EventEnvelope>,
    ) -> Result<(), EventStoreError> {
        let mut builder: QueryBuilder<Postgres> = QueryBuilder::new(
            "INSERT INTO event_outbox \
                 (event_id, aggregate_id, event_type, payload, occurred_at) ",
        );
        builder.push_values(events, |mut b, ev| {
            b.push_bind(ev.event_id)
                .push_bind(ev.aggregate_id)
                .push_bind(ev.event_type)
                .push_bind(ev.payload)
                .push_bind(ev.occurred_at);
        });
        let query = builder.build();
        query.execute(&mut *tx).await?;
        Ok(())
    }

    /// Fetch undispatched events in chronological order, optionally capped.
    #[instrument(skip(self))]
    pub async fn fetch_undispatched(
        &self,
        max_rows: i64,
    ) -> Result<Vec<EventEnvelope>, EventStoreError> {
        let rows = sqlx::query(
            r#"
            SELECT event_id, aggregate_id, event_type, payload, occurred_at
              FROM event_outbox
             WHERE dispatched_at IS NULL
          ORDER BY occurred_at ASC
             LIMIT $1
            "#,
        )
        .bind(max_rows)
        .fetch_all(&self.pool)
        .await?;

        let mut out = Vec::with_capacity(rows.len());
        for row in rows {
            out.push(EventEnvelope {
                event_id: row.try_get("event_id")?,
                aggregate_id: row.try_get("aggregate_id")?,
                event_type: row.try_get::<String, _>("event_type"),
                payload: row.try_get("payload")?,
                occurred_at: row.try_get("occurred_at")?,
            });
        }
        Ok(out)
    }

    /// Mark a batch of events as dispatched.
    #[instrument(skip(self, event_ids), fields(batch_size = event_ids.len()))]
    pub async fn mark_as_dispatched(
        &self,
        event_ids: &[EventId],
    ) -> Result<(), EventStoreError> {
        if event_ids.is_empty() {
            return Ok(());
        }

        let mut builder: QueryBuilder<Postgres> =
            QueryBuilder::new("UPDATE event_outbox SET dispatched_at = NOW() WHERE event_id IN (");
        let mut separated = builder.separated(", ");
        for id in event_ids {
            separated.push_bind(id);
        }
        separated.push_unseparated(")");
        let query = builder.build();
        query.execute(&self.pool).await?;

        Ok(())
    }
}

#[derive(Debug, Error)]
pub enum EventStoreError {
    #[error("database error: {0}")]
    Database(#[from] sqlx::Error),
    #[error("serde error: {0}")]
    Serde(#[from] serde_json::Error),
}

/* ============================================================================
   Broker Dispatcher
   ========================================================================== */

/// Configuration for the AMQP broker (RabbitMQ).
#[derive(Debug, Clone)]
pub struct BrokerConfig {
    pub amqp_uri: String,
    pub outbox_fetch_limit: i64,
    /// How often the dispatch loop wakes up if the outbox is empty.
    pub poll_interval: Duration,
    /// Exchange to which domain events are published.
    pub exchange: String,
}

/// Continuously polls the event outbox table,
/// publishes pending events to the message broker,
/// and then marks them as dispatched.
///
/// Implements *at-least-once* semantics by using RabbitMQ publisher confirms.
/// Combined with the Outbox table, this yields *exactly-once*.
///
pub struct BrokerDispatcher {
    store: EventStore,
    cfg: BrokerConfig,
}

impl BrokerDispatcher {
    pub fn new(store: EventStore, cfg: BrokerConfig) -> Self {
        Self { store, cfg }
    }

    /// Start the dispatcher in a background task.  Runs until `shutdown`
    /// is triggered via `tokio::signal`.
    pub async fn run_forever(&self) -> Result<(), DispatcherError> {
        // Lazily acquire connection; re-establish on errors.
        loop {
            match self.connect_and_run().await {
                Ok(_) => break,
                Err(DispatcherError::AMQPReconnect) => {
                    warn!("lost AMQP connection; retrying in 5s");
                    time::sleep(Duration::from_secs(5)).await;
                    continue;
                }
                Err(e) => return Err(e),
            }
        }
        Ok(())
    }

    #[instrument(skip_all)]
    async fn connect_and_run(&self) -> Result<(), DispatcherError> {
        info!("connecting to AMQP broker");
        let conn = Connection::connect(
            &self.cfg.amqp_uri,
            ConnectionProperties::default().with_default_executor(8),
        )
        .await
        .map_err(DispatcherError::AMQP)?;
        let channel = conn.create_channel().await.map_err(DispatcherError::AMQP)?;

        // Ensure the fan-out (topic) exchange exists.
        channel
            .exchange_declare(
                &self.cfg.exchange,
                lapin::ExchangeKind::Topic,
                lapin::options::ExchangeDeclareOptions::default(),
                Default::default(),
            )
            .await
            .map_err(DispatcherError::AMQP)?;

        info!("dispatcher connected; entering main loop");
        loop {
            let events = self
                .store
                .fetch_undispatched(self.cfg.outbox_fetch_limit)
                .await?;
            if events.is_empty() {
                time::sleep(self.cfg.poll_interval).await;
                continue;
            }

            self.publish_batch(&channel, &events).await?;
            self.store
                .mark_as_dispatched(&events.iter().map(|e| e.event_id).collect::<Vec<_>>())
                .await?;
        }
    }

    #[instrument(skip_all, fields(batch_size = events.len()))]
    async fn publish_batch(
        &self,
        channel: &Channel,
        events: &[EventEnvelope],
    ) -> Result<(), DispatcherError> {
        for ev in events {
            // Use the event_type as routing key (e.g., submission.received)
            let confirm: Confirmation = channel
                .basic_publish(
                    &self.cfg.exchange,
                    &ev.event_type,
                    BasicPublishOptions::default(),
                    serde_json::to_vec(ev)?,
                    BasicProperties::default()
                        .with_message_id(ev.event_id.to_string().into())
                        .with_content_type("application/json".into()),
                )
                .await
                .map_err(DispatcherError::AMQP)?
                .await
                .map_err(DispatcherError::AMQP)?;
            if confirm.is_nack() {
                error!(event_id = %ev.event_id, "broker NACKed message");
                return Err(DispatcherError::AMQPConfirm);
            }
            debug!(event_id = %ev.event_id, "published");
        }
        Ok(())
    }
}

#[derive(Debug, Error)]
pub enum DispatcherError {
    #[error("AMQP error: {0}")]
    AMQP(#[from] lapin::Error),

    #[error("AMQP publisher confirm failed")]
    AMQPConfirm,

    #[error("AMQP connection lost")]
    AMQPReconnect,

    #[error(transparent)]
    Store(#[from] EventStoreError),

    #[error("serialization error: {0}")]
    Serde(#[from] serde_json::Error),
}

/* ============================================================================
   Integration Example (for Service Layer)
   ========================================================================== */

/// Add events to the outbox inside the service layer.
///
/// This generic helper saves the service from having to know
/// about the low-level event store API.
#[instrument(skip_all, fields(event_type = E::EVENT_TYPE))]
pub async fn record_event<E>(
    pool: &PgPool,
    event: E,
) -> Result<(), EventStoreError>
where
    E: DomainEvent,
{
    let envelope = event.into_envelope();
    let mut tx = pool.begin().await?;
    let store = EventStore::new(pool.clone());
    store.append(&mut tx, std::iter::once(envelope)).await?;
    tx.commit().await?;
    Ok(())
}

/* ============================================================================
   Tests (requires `cargo test -- --nocapture`)
   ========================================================================== */

#[cfg(test)]
mod tests {
    use super::*;
    use sqlx::Executor;

    #[tokio::test]
    async fn can_append_and_fetch() -> anyhow::Result<()> {
        // In CI we use an ephemeral test container; here we assume $DATABASE_URL set.
        let pool = PgPool::connect(&std::env::var("DATABASE_URL")?).await?;

        // Ensure table exists (idempotent).
        pool.execute(
            r#"
            CREATE TABLE IF NOT EXISTS event_outbox(
                event_id        uuid PRIMARY KEY,
                aggregate_id    uuid NOT NULL,
                event_type      text NOT NULL,
                payload         jsonb NOT NULL,
                occurred_at     timestamptz NOT NULL,
                dispatched_at   timestamptz
            );
        "#,
        )
        .await?;

        let store = EventStore::new(pool.clone());
        let mut tx = pool.begin().await?;

        let evt = LearningPulseCreated {
            pulse_id: Uuid::new_v4(),
            author_id: Uuid::new_v4(),
            title: "Intro to Rust".into(),
        }
        .into_envelope();

        store.append(&mut tx, std::iter::once(evt.clone())).await?;
        tx.commit().await?;

        let fetched = store.fetch_undispatched(10).await?;
        assert_eq!(fetched.len(), 1);
        assert_eq!(fetched[0].event_type, "learning_pulse.created");
        Ok(())
    }
}
```
```rust
//! module_14.rs
//!
//! Hyperparameter Tuning subsystem for the VisuTility Orchestrator.
//! -----------------------------------------------------------------------------
//! • Implements Strategy Pattern to swap tuning algorithms at runtime
//! • Implements Observer Pattern to emit intermediate + final tuning artifacts
//! • Offers serializable `SearchSpace` and `HyperparameterSet` structures
//! • Resilient error handling using `thiserror`
//!
//! NOTE: This file purposefully avoids external async runtimes to keep it
//! self-contained, but it is `Send + Sync` ready for multi-threaded execution.

use rand::distributions::{Distribution, Uniform};
use rand::rngs::StdRng;
use rand::{Rng, SeedableRng};
use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use std::fmt::{self, Display};
use std::sync::{Arc, RwLock};
use thiserror::Error;

/// Type alias for clarity.
pub type MetricScore = f64;

/// Wrapper struct around a numeric hyper-parameter range.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct NumericRange {
    pub min: f64,
    pub max: f64,
    pub step: Option<f64>, // None => continuous
}

impl NumericRange {
    pub fn contains(&self, value: f64) -> bool {
        value >= self.min && value <= self.max
    }
}

/// SearchSpace maps hyper-parameter names to their feasible range.
#[derive(Debug, Clone, Serialize, Deserialize, Default)]
pub struct SearchSpace(pub HashMap<String, NumericRange>);

impl SearchSpace {
    pub fn is_empty(&self) -> bool {
        self.0.is_empty()
    }

    /// Returns the number of discrete combinations for ranges with `step`.
    /// For ranges without step, returns `None`.
    pub fn cardinality(&self) -> Option<usize> {
        let mut total: usize = 1;
        for range in self.0.values() {
            match range.step {
                Some(step) => {
                    let count = (((range.max - range.min) / step).floor() as usize) + 1;
                    total = total.saturating_mul(count);
                }
                None => return None,
            }
        }
        Some(total)
    }
}

/// Concrete set of hyper-parameters.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct HyperparameterSet(pub HashMap<String, f64>);

impl Display for HyperparameterSet {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        let entries: Vec<String> = self
            .0
            .iter()
            .map(|(k, v)| format!("{}={:.4}", k, v))
            .collect();
        write!(f, "{}", entries.join(", "))
    }
}

/// Evaluates the model with the provided hyper-parameters.
pub trait MetricEvaluator: Send + Sync {
    fn evaluate(&self, params: &HyperparameterSet) -> Result<MetricScore, TuningError>;
}

/// Observer that receives updates during tuning.
pub trait TuningObserver: Send + Sync {
    fn on_evaluation(
        &self,
        params: &HyperparameterSet,
        score: MetricScore,
    ) -> Result<(), TuningError>;
    fn on_complete(
        &self,
        best_params: &HyperparameterSet,
        best_score: MetricScore,
    ) -> Result<(), TuningError>;
}

/// Strategy Pattern: encapsulates a tuning algorithm.
pub trait HyperparameterTuningStrategy: Send + Sync {
    fn tune(
        &self,
        search_space: &SearchSpace,
        metric: &dyn MetricEvaluator,
        observer: Option<Arc<dyn TuningObserver>>,
        max_iters: usize,
    ) -> Result<HyperparameterSet, TuningError>;
}

/// Grid-search implementation.
pub struct ExhaustiveGridSearch;

impl HyperparameterTuningStrategy for ExhaustiveGridSearch {
    fn tune(
        &self,
        search_space: &SearchSpace,
        metric: &dyn MetricEvaluator,
        observer: Option<Arc<dyn TuningObserver>>,
        max_iters: usize,
    ) -> Result<HyperparameterSet, TuningError> {
        // Pre-compute discrete grid.
        let mut grid: Vec<HyperparameterSet> = vec![HyperparameterSet(HashMap::new())];
        for (name, range) in &search_space.0 {
            if let Some(step) = range.step {
                let mut next_grid = Vec::new();
                let mut val = range.min;
                while val <= range.max {
                    for base in &grid {
                        let mut new_map = base.0.clone();
                        new_map.insert(name.clone(), val);
                        next_grid.push(HyperparameterSet(new_map));
                    }
                    val += step;
                }
                grid = next_grid;
            } else {
                return Err(TuningError::InvalidSearchSpace(format!(
                    "Continuous range `{}` not supported in exhaustive grid search",
                    name
                )));
            }
        }

        if grid.is_empty() {
            return Err(TuningError::InvalidSearchSpace(
                "Search space resulted in empty grid".into(),
            ));
        }

        let mut best_score = f64::NEG_INFINITY;
        let mut best_params = grid[0].clone();

        for (i, params) in grid.into_iter().enumerate().take(max_iters) {
            let score = metric.evaluate(&params)?;
            if let Some(obs) = &observer {
                obs.on_evaluation(&params, score)?;
            }

            if score > best_score {
                best_score = score;
                best_params = params;
            }

            if i + 1 >= max_iters {
                break;
            }
        }

        if let Some(obs) = &observer {
            obs.on_complete(&best_params, best_score)?;
        }

        Ok(best_params)
    }
}

/// Random-search implementation.
pub struct RandomSearch {
    rng: RwLock<StdRng>,
}

impl RandomSearch {
    pub fn new(seed: u64) -> Self {
        Self {
            rng: RwLock::new(StdRng::seed_from_u64(seed)),
        }
    }
}

impl HyperparameterTuningStrategy for RandomSearch {
    fn tune(
        &self,
        search_space: &SearchSpace,
        metric: &dyn MetricEvaluator,
        observer: Option<Arc<dyn TuningObserver>>,
        max_iters: usize,
    ) -> Result<HyperparameterSet, TuningError> {
        if search_space.is_empty() {
            return Err(TuningError::InvalidSearchSpace(
                "Search space empty".into(),
            ));
        }

        let mut best_score = f64::NEG_INFINITY;
        let mut best_params = None;

        for _ in 0..max_iters {
            let mut params = HashMap::new();
            {
                let mut rng = self
                    .rng
                    .write()
                    .map_err(|_| TuningError::Internal("RNG poisoned".into()))?;
                for (name, range) in &search_space.0 {
                    let val = if let Some(step) = range.step {
                        // Discrete uniform
                        let n_steps =
                            (((range.max - range.min) / step).floor() as usize).max(1);
                        let idx = rng.gen_range(0..=n_steps);
                        range.min + (idx as f64) * step
                    } else {
                        // Continuous uniform
                        let between = Uniform::new_inclusive(range.min, range.max);
                        between.sample(&mut *rng)
                    };
                    params.insert(name.clone(), val);
                }
            }

            let param_set = HyperparameterSet(params);
            let score = metric.evaluate(&param_set)?;

            if let Some(obs) = &observer {
                obs.on_evaluation(&param_set, score)?;
            }

            if score > best_score {
                best_score = score;
                best_params = Some(param_set);
            }
        }

        let best_params = best_params.ok_or_else(|| {
            TuningError::Internal("RandomSearch produced no parameter sets".into())
        })?;

        if let Some(obs) = &observer {
            obs.on_complete(&best_params, best_score)?;
        }

        Ok(best_params)
    }
}

/// Public façade used by outside callers.
/// The façade hides concrete algorithms and exposes a minimal surface.
pub struct Tuner {
    strategy: Box<dyn HyperparameterTuningStrategy>,
    observer: Option<Arc<dyn TuningObserver>>,
}

impl Tuner {
    pub fn new<S>(strategy: S) -> Self
    where
        S: HyperparameterTuningStrategy + 'static,
    {
        Self {
            strategy: Box::new(strategy),
            observer: None,
        }
    }

    pub fn with_observer(mut self, observer: Arc<dyn TuningObserver>) -> Self {
        self.observer = Some(observer);
        self
    }

    pub fn tune(
        &self,
        search_space: &SearchSpace,
        metric: &dyn MetricEvaluator,
        max_iters: usize,
    ) -> Result<HyperparameterSet, TuningError> {
        self.strategy
            .tune(search_space, metric, self.observer.clone(), max_iters)
    }
}

/// Errors produced by the tuning subsystem.
#[derive(Debug, Error)]
pub enum TuningError {
    #[error("Invalid search space: {0}")]
    InvalidSearchSpace(String),

    #[error("Metric evaluation failed: {0}")]
    MetricEvaluation(String),

    #[error("Observer failed: {0}")]
    ObserverFailure(String),

    #[error("Internal error: {0}")]
    Internal(String),
}

/// Dummy metric evaluator for integration tests.
#[cfg(test)]
struct ParabolaMetric;

#[cfg(test)]
impl MetricEvaluator for ParabolaMetric {
    fn evaluate(&self, params: &HyperparameterSet) -> Result<MetricScore, TuningError> {
        let x = params
            .0
            .get("x")
            .ok_or_else(|| TuningError::MetricEvaluation("x not provided".into()))?;
        let y = -(*x - 3.0).powi(2) + 10.0; // maximized at x = 3, value 10
        Ok(y)
    }
}

/// Simple observer that collects history for assertions.
#[cfg(test)]
struct RecordingObserver {
    pub records: Arc<RwLock<Vec<(HyperparameterSet, MetricScore)>>>,
}

#[cfg(test)]
impl RecordingObserver {
    pub fn new() -> Self {
        Self {
            records: Arc::new(RwLock::new(Vec::new())),
        }
    }
}

#[cfg(test)]
impl TuningObserver for RecordingObserver {
    fn on_evaluation(
        &self,
        params: &HyperparameterSet,
        score: MetricScore,
    ) -> Result<(), TuningError> {
        self.records
            .write()
            .map_err(|_| TuningError::ObserverFailure("poisoned".into()))?
            .push((params.clone(), score));
        Ok(())
    }

    fn on_complete(
        &self,
        _best_params: &HyperparameterSet,
        _best_score: MetricScore,
    ) -> Result<(), TuningError> {
        Ok(())
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_grid_search_finds_optimum() {
        let search_space = SearchSpace(
            vec![(
                "x".to_string(),
                NumericRange {
                    min: -10.0,
                    max: 10.0,
                    step: Some(1.0),
                },
            )]
            .into_iter()
            .collect(),
        );

        let metric = ParabolaMetric;
        let strategy = ExhaustiveGridSearch;
        let observer = RecordingObserver::new();

        let tuner = Tuner::new(strategy).with_observer(Arc::new(observer));
        let best = tuner.tune(&search_space, &metric, 100).unwrap();

        let best_x = *best.0.get("x").unwrap();
        assert_eq!(best_x, 3.0);
    }

    #[test]
    fn test_random_search_runs() {
        let search_space = SearchSpace(
            vec![(
                "x".to_string(),
                NumericRange {
                    min: -5.0,
                    max: 5.0,
                    step: None,
                },
            )]
            .into_iter()
            .collect(),
        );

        let metric = ParabolaMetric;
        let strategy = RandomSearch::new(42);
        let tuner = Tuner::new(strategy);
        let _ = tuner.tune(&search_space, &metric, 50).unwrap();
    }
}
```
```rust
//! src/module_19.rs
//!
//! Modelâ€“Monitoring and Automated-Retraining Orchestrator.
//!
//! This module wires together an Observer-pattern based metric bus,
//! threshold-based retraining strategies, and a retraining trigger that
//! publishes jobs to the Model-Ops layer.  
//!
//! It is **runtime-agnostic** (uses Tokio when available, but falls back to
//! `std`), fully asynchronous, and provides an ergonomic API for other parts
//! of the VisuTility stack.

use std::{
    fmt,
    sync::Arc,
    time::{Duration, SystemTime},
};

use async_trait::async_trait;
use serde::{Deserialize, Serialize};
use thiserror::Error;
use tokio::{
    select,
    sync::{broadcast, mpsc, oneshot},
};
use tracing::{debug, error, info, instrument, warn};

/// Size of the broadcast channel used internally by [`EventBus`].
const METRIC_BUS_CAPACITY: usize = 128;
/// Size of the mpsc channel used to notify the external retrainer service.
const RETRAIN_TASK_CAPACITY: usize = 32;

// ===========================================================================
// Domain Types
// ===========================================================================

/// MetricEvent captures the minimal payload broadcast by the inference-service.
#[derive(Debug, Clone, Serialize, Deserialize)]
#[serde(tag = "type", rename_all = "snake_case")]
pub enum MetricEvent {
    Classification {
        model_name: String,
        version: String,
        accuracy: f32,
        latency_ms: u64,
        timestamp: SystemTime,
    },
    Regression {
        model_name: String,
        version: String,
        mae: f32,
        latency_ms: u64,
        timestamp: SystemTime,
    },
}

impl MetricEvent {
    /// Returns a unique identifier of the emitting model artifact.
    pub fn artifact_id(&self) -> (&str, &str) {
        match self {
            MetricEvent::Classification { model_name, version, .. }
            | MetricEvent::Regression { model_name, version, .. } => (model_name, version),
        }
    }
}

// ===========================================================================
// Error Handling
// ===========================================================================

#[derive(Debug, Error)]
pub enum MonitorError {
    #[error("Failed to broadcast metric: {0}")]
    Broadcast(#[from] broadcast::error::SendError<MetricEvent>),
    #[error("Retraining trigger failed: {0}")]
    RetrainTrigger(String),
    #[error("Observer channel error: {0}")]
    ObserverChannel(#[from] broadcast::error::RecvError),
    #[error("Task join error: {0}")]
    Join(#[from] tokio::task::JoinError),
}

// ===========================================================================
// Observer Pattern
// ===========================================================================

/// Asynchronous Observer for [`MetricEvent`]s.
#[async_trait]
pub trait Observer: Send + Sync {
    async fn on_event(&self, event: MetricEvent) -> Result<(), MonitorError>;
}

/// Concrete event bus that decouples metric producers and observers.
pub struct EventBus {
    sender: broadcast::Sender<MetricEvent>,
}

impl EventBus {
    pub fn new() -> Self {
        let (sender, _) = broadcast::channel(METRIC_BUS_CAPACITY);
        Self { sender }
    }

    /// Used by inference services to push new metrics into the system.
    pub fn publish(&self, event: MetricEvent) -> Result<(), MonitorError> {
        Ok(self.sender.send(event)?)
    }

    /// Subscribe an observer. The observer will be spawned on the Tokio runtime.
    pub fn subscribe<O>(&self, observer: Arc<O>)
    where
        O: Observer + 'static,
    {
        let mut rx = self.sender.subscribe();
        tokio::spawn(async move {
            loop {
                match rx.recv().await {
                    Ok(event) => {
                        if let Err(e) = observer.on_event(event).await {
                            error!(error = ?e, "Observer failed");
                        }
                    }
                    Err(broadcast::error::RecvError::Closed) => break,
                    Err(broadcast::error::RecvError::Lagged(l)) => {
                        warn!(dropped = l, "Metric bus lagged; dropped events");
                    }
                }
            }
        });
    }
}

// ===========================================================================
// Strategy Pattern
// ===========================================================================

/// Input necessary for a retraining decision.
#[derive(Debug)]
pub struct MetricSnapshot {
    pub event: MetricEvent,
}

/// Return-type describing the strategy decision.
#[derive(Debug, Clone, PartialEq, Eq)]
pub enum StrategyDecision {
    NoOp,
    TriggerRetrain { reason: String },
}

/// Abstraction for pluggable retraining decision strategies.
#[async_trait]
pub trait RetrainingStrategy: Send + Sync {
    async fn evaluate(&self, snapshot: &MetricSnapshot) -> StrategyDecision;
}

/// Simple threshold-based strategy suitable for PoC deployments.
/// Can be replaced by more advanced, e.g. drift-detection strategies.
#[derive(Debug, Clone)]
pub struct ThresholdStrategy {
    /// Accuracy/MAE below which retraining is advised.
    pub accuracy_threshold: f32,
    pub mae_threshold: f32,
}

impl Default for ThresholdStrategy {
    fn default() -> Self {
        Self {
            accuracy_threshold: 0.80,
            mae_threshold: 5.0,
        }
    }
}

#[async_trait]
impl RetrainingStrategy for ThresholdStrategy {
    #[instrument(skip_all)]
    async fn evaluate(&self, snapshot: &MetricSnapshot) -> StrategyDecision {
        match &snapshot.event {
            MetricEvent::Classification { accuracy, .. } if *accuracy < self.accuracy_threshold => {
                StrategyDecision::TriggerRetrain {
                    reason: format!(
                        "accuracy {:.4} fell below threshold {:.4}",
                        accuracy, self.accuracy_threshold
                    ),
                }
            }
            MetricEvent::Regression { mae, .. } if *mae > self.mae_threshold => {
                StrategyDecision::TriggerRetrain {
                    reason: format!(
                        "mae {:.4} exceeded threshold {:.4}",
                        mae, self.mae_threshold
                    ),
                }
            }
            _ => StrategyDecision::NoOp,
        }
    }
}

// ===========================================================================
// Retraining Trigger (Observer)
// ===========================================================================

/// Command sent to the Model-Ops layer.
#[derive(Debug, Serialize, Deserialize)]
pub struct RetrainCommand {
    pub model_name: String,
    pub base_version: String,
    pub issued_at: SystemTime,
    pub reason: String,
}

/// Observer that converts metrics into retraining jobs using the provided strategy.
pub struct RetrainTrigger<S> {
    strategy: S,
    task_tx: mpsc::Sender<RetrainCommand>,
}

impl<S> RetrainTrigger<S> {
    pub fn new(strategy: S, task_tx: mpsc::Sender<RetrainCommand>) -> Self {
        Self { strategy, task_tx }
    }
}

#[async_trait]
impl<S> Observer for RetrainTrigger<S>
where
    S: RetrainingStrategy + 'static,
{
    #[instrument(skip_all)]
    async fn on_event(&self, event: MetricEvent) -> Result<(), MonitorError> {
        let snapshot = MetricSnapshot { event: event.clone() };
        match self.strategy.evaluate(&snapshot).await {
            StrategyDecision::TriggerRetrain { reason } => {
                let (model_name, base_version) = event.artifact_id();
                let cmd = RetrainCommand {
                    model_name: model_name.to_owned(),
                    base_version: base_version.to_owned(),
                    issued_at: SystemTime::now(),
                    reason,
                };

                self.task_tx
                    .send(cmd)
                    .await
                    .map_err(|e| MonitorError::RetrainTrigger(format!("{e}")))?;
            }
            StrategyDecision::NoOp => { /* NO-OP */ }
        }

        Ok(())
    }
}

// ===========================================================================
// Public Orchestrator API
// ===========================================================================

/// High-level handle returned to application code.
pub struct MonitorHandle {
    bus: EventBus,
    /// Receiver side exposed so that the Model-Ops layer can pick new jobs.
    pub retrain_rx: mpsc::Receiver<RetrainCommand>,
}

impl MonitorHandle {
    /// Push a new metric event into the monitoring pipeline.
    pub fn emit(&self, event: MetricEvent) -> Result<(), MonitorError> {
        self.bus.publish(event)?;
        Ok(())
    }
}

/// Build the monitoring system with default parameters.
pub fn init_monitoring() -> MonitorHandle {
    let bus = EventBus::new();

    let (task_tx, task_rx) = mpsc::channel::<RetrainCommand>(RETRAIN_TASK_CAPACITY);
    let strategy = ThresholdStrategy::default();
    let trigger = Arc::new(RetrainTrigger::new(strategy, task_tx));
    bus.subscribe(trigger);

    MonitorHandle { bus, retrain_rx: task_rx }
}

// ===========================================================================
// Example (would live in integration tests/product code).
// ===========================================================================

#[cfg(test)]
mod tests {
    use super::*;
    use tokio::time::timeout;

    #[tokio::test]
    async fn it_triggers_retraining_when_accuracy_drops() {
        let monitor = init_monitoring();

        let bad_metric = MetricEvent::Classification {
            model_name: "object-detector".into(),
            version: "v1.2.3".into(),
            accuracy: 0.50, // well below threshold
            latency_ms: 42,
            timestamp: SystemTime::now(),
        };

        monitor.emit(bad_metric).unwrap();

        // Wait at most 1 second for the retraining command.
        let recv = timeout(Duration::from_secs(1), monitor.retrain_rx.recv());
        let cmd = recv.await.unwrap().unwrap();

        assert_eq!(cmd.model_name, "object-detector");
        assert_eq!(cmd.base_version, "v1.2.3");
        assert!(cmd.reason.contains("accuracy"));
    }

    #[tokio::test]
    async fn it_ignores_good_metrics() {
        let monitor = init_monitoring();

        let good_metric = MetricEvent::Classification {
            model_name: "quality-inspector".into(),
            version: "v2.0.0".into(),
            accuracy: 0.95, // above threshold
            latency_ms: 30,
            timestamp: SystemTime::now(),
        };

        monitor.emit(good_metric).unwrap();

        // Ensure no message arrives within 300ms.
        let recv = timeout(Duration::from_millis(300), monitor.retrain_rx.recv());
        assert!(recv.await.is_err());
    }
}
```
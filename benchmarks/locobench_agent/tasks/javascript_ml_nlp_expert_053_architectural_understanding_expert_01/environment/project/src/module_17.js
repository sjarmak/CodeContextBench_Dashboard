```javascript
/**
 * src/module_17.js
 *
 * A production-grade, event-driven micro-pipeline that
 * 1) consumes raw social-network events from Kafka,
 * 2) performs lightweight feature engineering,
 * 3) resolves the optimal model version from the Model Registry,
 * 4) delegates inference to a pluggable Strategy implementation, and
 * 5) emits enriched analysis records downstream.
 *
 * Patterns showcased:
 *   - Observer (RxJS)
 *   - Factory & Strategy (model-serving layer)
 *   - Caching (LRU for registry look-ups)
 *
 * Note: External integrations (Kafka, MLflow, HuggingFace, etc.) have
 * been stubbed where necessary to keep the module self-contained while
 * retaining realistic structure and error handling.
 */

'use strict';

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 * Imports
 * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
const { Kafka } = require('kafkajs');                     // Apache Kafka client
const { Subject, from, of, EMPTY, iif } = require('rxjs');
const {
  map,
  mergeMap,
  catchError,
  timeout,
  filter,
  tap,
} = require('rxjs/operators');
const LRU = require('lru-cache');                         // Tiny in-memory cache
const _get = require('lodash/get');                       // Safe object access
const axios = require('axios').default;                   // HTTP client

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 * Constants & Config
 * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
const CONFIG = {
  kafka: {
    brokers: process.env.KAFKA_BROKERS?.split(',') || ['localhost:9092'],
    groupId: process.env.KAFKA_GROUP_ID || 'agorapulse-model-router',
    sourceTopic: process.env.KAFKA_SOURCE_TOPIC || 'social.events',
    sinkTopic: process.env.KAFKA_SINK_TOPIC || 'social.analysis',
  },
  registry: {
    baseUrl: process.env.MODEL_REGISTRY_URL || 'http://mlflow.registry.local',
    cacheTtlMs: 60_000, // 1 minute
  },
  inference: {
    timeoutMs: 2_500,
  },
};

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 * Utilities
 * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */

/**
 * Simple cancellation helper using AbortController.
 * @param {number} ms - Milliseconds before aborting.
 * @returns {AbortController}
 */
function createTimeoutAbortController(ms) {
  const controller = new AbortController();
  const timer = setTimeout(() => controller.abort(), ms);
  // Clear timer on end
  controller.signal.addEventListener('abort', () => clearTimeout(timer));
  return controller;
}

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 * Model Registry Client (MLflow, etc.)
 * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
class ModelRegistryClient {
  constructor({ baseUrl, cacheTtlMs = 60_000 } = {}) {
    this.baseUrl = baseUrl;
    this.cache = new LRU({
      max: 500,
      ttl: cacheTtlMs,
    });
  }

  /**
   * Resolve a model given contextual metadata.
   * The cache key is a hashed concatenation of query params.
   * @param {Object} query
   * @param {string} query.task - e.g. 'sentiment', 'toxicity'
   * @param {string} query.language - ISO 639-1, e.g. 'en'
   * @param {Object} [query.options] - Additional filter flags
   * @returns {Promise<ModelMeta>}
   */
  async resolveModel(query) {
    const key = JSON.stringify(query);
    if (this.cache.has(key)) return this.cache.get(key);

    try {
      const { task, language, options } = query;
      const resp = await axios.get(`${this.baseUrl}/api/resolve`, {
        params: { task, language, ...options },
        timeout: 5_000,
      });
      this.cache.set(key, resp.data);
      return resp.data;
    } catch (err) {
      console.error('[Model Registry] Resolve error:', err.message);
      throw err;
    }
  }
}

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 * Strategy Pattern â€‘ Model serving back-ends
 * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */

/**
 * @interface
 * @typedef {Object} ModelStrategy
 * @property {(features: Object) => Promise<Object>} infer
 * @property {() => string} id
 */

class BaseModelStrategy {
  constructor(modelMeta) {
    this.modelMeta = modelMeta;
  }
  id() {
    return `${this.constructor.name}:${this.modelMeta?.version || 'unknown'}`;
  }
  /* eslint-disable-next-line class-methods-use-this */
  async infer() {
    throw new Error('infer() must be implemented by subclass');
  }
}

class HuggingFaceStrategy extends BaseModelStrategy {
  async infer(features) {
    const controller = createTimeoutAbortController(CONFIG.inference.timeoutMs);
    try {
      const resp = await axios.post(
        this.modelMeta.endpointUrl,
        { inputs: features },
        { signal: controller.signal }
      );
      return resp.data;
    } catch (err) {
      console.error(`[HF Strategy] Inference failed: ${err.message}`);
      throw err;
    }
  }
}

class LocalGrpcStrategy extends BaseModelStrategy {
  async infer(features) {
    // Simulated gRPC call via axios to keep demo self-contained.
    try {
      const resp = await axios.post(
        this.modelMeta.endpointUrl,
        { payload: features },
        { timeout: CONFIG.inference.timeoutMs }
      );
      return resp.data;
    } catch (err) {
      console.error(`[gRPC Strategy] Inference failed: ${err.message}`);
      throw err;
    }
  }
}

/**
 * Factory resolving the appropriate Strategy implementation
 * given a model metadata descriptor.
 */
class StrategyFactory {
  /**
   * @param {ModelMeta} modelMeta
   * @returns {ModelStrategy}
   */
  static create(modelMeta) {
    const { provider } = modelMeta;

    switch (provider) {
      case 'huggingface':
        return new HuggingFaceStrategy(modelMeta);
      case 'local-grpc':
        return new LocalGrpcStrategy(modelMeta);
      default:
        throw new Error(`Unknown model provider: ${provider}`);
    }
  }
}

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 * Feature Engineering
 * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */

/**
 * Extracts a minimal feature set from the raw event payload.
 * @param {Object} event - Raw Kafka message value (JSON).
 */
function buildFeatures(event) {
  const text = _get(event, 'content.text', '');
  const lang = _get(event, 'lang', 'en');
  const authorMeta = _get(event, 'author', {});
  return {
    text,
    language: lang,
    followers: authorMeta.followers || 0,
    emojis: (text.match(/\p{Emoji_Presentation}/gu) || []).length,
  };
}

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 * Kafka Source & Sink
 * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */

class KafkaPipeline {
  constructor({ registryClient }) {
    this.registryClient = registryClient;

    // Lazily created because kafkajs internally establishes connections.
    this.kafka = new Kafka({ brokers: CONFIG.kafka.brokers });
    this.consumer = this.kafka.consumer({ groupId: CONFIG.kafka.groupId });
    this.producer = this.kafka.producer();
    this.event$ = new Subject();
  }

  async init() {
    await Promise.all([this.consumer.connect(), this.producer.connect()]);
    await this.consumer.subscribe({ topic: CONFIG.kafka.sourceTopic });
  }

  /**
   * Start streaming loop
   */
  async start() {
    await this.init();

    // Consume in classic callback style and push into RxJS subject.
    await this.consumer.run({
      eachMessage: async ({ message }) => {
        try {
          const payload = JSON.parse(message.value.toString());
          this.event$.next(payload);
        } catch (err) {
          console.error('Failed to parse message:', err.message);
        }
      },
    });

    // Build reactive pipeline
    this.event$
      .pipe(
        // Filter for events with textual content
        filter((e) => !!_get(e, 'content.text')),
        map((event) => ({
          event,
          features: buildFeatures(event),
        })),
        // Resolve model from registry
        mergeMap(async ({ event, features }) => {
          const task = 'sentiment'; // For demo; could be dynamic per event
          const modelMeta = await this.registryClient.resolveModel({
            task,
            language: features.language,
          });

          return { event, features, modelMeta };
        }),
        // Instantiate serving strategy
        map(({ event, features, modelMeta }) => ({
          event,
          features,
          model: StrategyFactory.create(modelMeta),
        })),
        // Delegate inference
        mergeMap(({ event, features, model }) =>
          from(model.infer(features)).pipe(
            timeout(CONFIG.inference.timeoutMs),
            map((prediction) => ({ event, prediction, modelId: model.id() })),
            catchError((err) => {
              console.error('Inference error (swallowed, continues):', err.message);
              return EMPTY; // skip failed record
            })
          )
        ),
        // Emit enriched record downstream
        mergeMap(({ event, prediction, modelId }) => {
          const enriched = {
            ...event,
            analytics: {
              modelId,
              ts: Date.now(),
              ...prediction,
            },
          };
          return from(
            this.producer.send({
              topic: CONFIG.kafka.sinkTopic,
              messages: [{ value: JSON.stringify(enriched) }],
            })
          ).pipe(
            tap(() => console.debug(`Enriched event forwarded by ${modelId}`)),
            catchError((err) => {
              console.error('Failed to publish enriched event:', err.message);
              return EMPTY;
            })
          );
        })
      )
      .subscribe({
        error: (err) => {
          console.error('Pipeline fatal error:', err);
          process.exitCode = 1;
        },
      });

    console.info('ðŸš€ Kafka pipeline active');
  }

  async shutdown() {
    await Promise.all([this.consumer.disconnect(), this.producer.disconnect()]);
    console.info('Kafka pipeline shut down gracefully');
  }
}

/* â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 * Bootstrap
 * â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ */
if (require.main === module) {
  (async () => {
    const registryClient = new ModelRegistryClient(CONFIG.registry);
    const pipeline = new KafkaPipeline({ registryClient });

    process.once('SIGINT', async () => {
      console.info('SIGINT caught â€“ terminatingâ€¦');
      await pipeline.shutdown();
      process.exit(0);
    });

    process.once('SIGTERM', async () => {
      console.info('SIGTERM caught â€“ terminatingâ€¦');
      await pipeline.shutdown();
      process.exit(0);
    });

    try {
      await pipeline.start();
    } catch (err) {
      console.error('Pipeline failed to start:', err);
      process.exit(1);
    }
  })();
}

module.exports = {
  KafkaPipeline,
  ModelRegistryClient,
  StrategyFactory,
  HuggingFaceStrategy,
  LocalGrpcStrategy,
};
```
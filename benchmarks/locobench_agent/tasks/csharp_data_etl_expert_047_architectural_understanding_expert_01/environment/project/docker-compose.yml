```yaml
# ==========================================================================================
#  PaletteStream ETL Canvas – Local/CI Integration Test Stack
#
#  This docker-compose file provisions all infrastructure dependencies required to run
#  automated integration / component tests for the PaletteStream micro-service mesh.
#
#  Services
#  --------
#  • Zookeeper, Kafka & Schema-Registry – event streaming backbone
#  • PostgreSQL                                – metadata / job tracking store
#  • Redis (Hangfire)                          – background-job scheduler & state
#  • MinIO + bucket bootstrap                  – S3-compatible data-lake zones
#  • Prometheus + Grafana + OpenTelemetry      – metrics, traces, dashboards
#  • palette-etl-api                           – System-Under-Test (SUT)
#
#  NOTE: Containers are optimized for CI: fast startup, deterministic health-checks,
#  low resource footprint.  GPU/Arrow acceleration is disabled by default – override
#  via COMPOSE_PROFILES=gpu to enable.
# ==========================================================================================
version: "3.9"

x-common-env: &common-logging-env
  # Verbose logging for test runs
  ASPNETCORE_ENVIRONMENT: "Test"
  LOG_LEVEL: "Debug"

x-healthcheck-defaults: &health-defaults
  interval: 10s
  timeout: 5s
  retries: 10
  start_period: 10s

networks:
  etl-mesh:
    driver: bridge

volumes:
  minio-data:
  postgres-data:
  prometheus-data:

services:
  # -----------------------------
  #  Messaging Backbone
  # -----------------------------
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    networks: [ etl-mesh ]
    healthcheck:
      test: [ "CMD", "bash", "-c", "echo ruok | nc -w 2 localhost 2181 | grep imok" ]
      <<: *health-defaults

  kafka-broker:
    image: confluentinc/cp-kafka:7.5.0
    container_name: kafka-broker
    depends_on:
      zookeeper:
        condition: service_healthy
    ports:
      - "9092:9092"   # Expose for local debugging
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka-broker:9092,PLAINTEXT_HOST://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
    networks: [ etl-mesh ]
    healthcheck:
      test: [ "CMD", "bash", "-c", "kafka-topics --bootstrap-server localhost:9092 --list" ]
      <<: *health-defaults

  schema-registry:
    image: confluentinc/cp-schema-registry:7.5.0
    container_name: schema-registry
    depends_on:
      kafka-broker:
        condition: service_healthy
    environment:
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8081
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: PLAINTEXT://kafka-broker:9092
    networks: [ etl-mesh ]
    healthcheck:
      test: [ "CMD-SHELL", "curl --silent --fail http://localhost:8081/subjects || exit 1" ]
      <<: *health-defaults

  # -----------------------------
  #  Relational Store (Hangfire)
  # -----------------------------
  postgres:
    image: postgres:15-alpine
    container_name: postgres
    environment:
      POSTGRES_USER: pal_admin
      POSTGRES_PASSWORD: pal_pw
      POSTGRES_DB: palette_stream
    ports:
      - "5432:5432"
    volumes:
      - postgres-data:/var/lib/postgresql/data
    networks: [ etl-mesh ]
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready -U pal_admin" ]
      <<: *health-defaults

  redis:
    image: redis:7-alpine
    container_name: redis
    ports:
      - "6379:6379"
    networks: [ etl-mesh ]
    healthcheck:
      test: [ "CMD", "redis-cli", "ping" ]
      <<: *health-defaults

  # -----------------------------
  #  Data-Lake (S3 compatible)
  # -----------------------------
  minio:
    image: quay.io/minio/minio:RELEASE.2023-10-07T15-07-38Z
    container_name: minio
    command: server /data --console-address ":9001"
    ports:
      - "9000:9000"   # S3 API
      - "9001:9001"   # Console
    environment:
      MINIO_ROOT_USER: minio
      MINIO_ROOT_PASSWORD: minio123
    volumes:
      - minio-data:/data
    networks: [ etl-mesh ]
    healthcheck:
      test: [ "CMD", "mc", "ready", "local" ]
      <<: *health-defaults

  # Bootstrap buckets (raw, refined, curated) once MinIO is healthy
  minio-create-buckets:
    image: quay.io/minio/mc:RELEASE.2023-10-07T15-07-38Z
    container_name: minio-create-buckets
    depends_on:
      minio:
        condition: service_healthy
    entrypoint: >
      /bin/sh -c "
        mc alias set local http://minio:9000 minio minio123 && \
        (mc ls local/raw     || mc mb local/raw)     && \
        (mc ls local/refined || mc mb local/refined) && \
        (mc ls local/curated || mc mb local/curated)
      "
    networks: [ etl-mesh ]
    restart: "no"

  # -----------------------------
  #  Observability
  # -----------------------------
  otel-collector:
    image: otel/opentelemetry-collector-contrib:0.88.0
    container_name: otel-collector
    command: ["--config=/etc/otel-collector-config.yml"]
    volumes:
      - ./infrastructure/otel/otel-collector-config.yml:/etc/otel-collector-config.yml:ro
    ports:
      - "4317:4317"   # OTLP gRPC
      - "4318:4318"   # OTLP HTTP
    networks: [ etl-mesh ]
    healthcheck:
      test: [ "CMD-SHELL", "wget -qO- http://localhost:13133/healthz || exit 1" ]
      <<: *health-defaults

  prometheus:
    image: prom/prometheus:v2.47.1
    container_name: prometheus
    volumes:
      - ./infrastructure/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus-data:/prometheus
    ports:
      - "9090:9090"
    networks: [ etl-mesh ]

  grafana:
    image: grafana/grafana-oss:10.2.1
    container_name: grafana
    environment:
      GF_SECURITY_ADMIN_USER: admin
      GF_SECURITY_ADMIN_PASSWORD: admin
    ports:
      - "3000:3000"
    networks: [ etl-mesh ]
    depends_on:
      prometheus:
        condition: service_started

  # -----------------------------
  #  System-Under-Test (SUT)
  # -----------------------------
  palette-etl-api:
    container_name: palette-etl-api
    build:
      context: .
      dockerfile: src/PaletteStream.Api/Dockerfile
    profiles: ["default", "gpu"]   # Build once, runs in both CPU/GPU profiles
    depends_on:
      kafka-broker:
        condition: service_healthy
      schema-registry:
        condition: service_healthy
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      minio-create-buckets:
        condition: service_completed_successfully
    environment:
      <<: *common-logging-env
      # Connection Strings & URLs
      ConnectionStrings__Postgres: "Host=postgres;Database=palette_stream;Username=pal_admin;Password=pal_pw"
      Redis__Configuration: "redis:6379"
      Kafka__BootstrapServers: "kafka-broker:9092"
      Kafka__SchemaRegistryUrl: "http://schema-registry:8081"
      DataLake__S3__Endpoint: "http://minio:9000"
      DataLake__S3__AccessKey: "minio"
      DataLake__S3__SecretKey: "minio123"
      DataLake__S3__Region: "us-east-1"
      ASPNETCORE_URLS: "http://0.0.0.0:8080"
      OTEL_EXPORTER_OTLP_ENDPOINT: "http://otel-collector:4317"
    ports:
      - "8080:8080"
    networks: [ etl-mesh ]
    healthcheck:
      test: [ "CMD-SHELL", "wget -qO- http://localhost:8080/healthz || exit 1" ]
      <<: *health-defaults

# ==========================================================================================
#  Usage
#  -----
#  • docker compose up -d           # fire up the full stack
#  • docker compose down -v         # tear down and wipe data volumes
#  • COMPOSE_PROFILES=gpu <cmd>     # enable GPU-accelerated profile (ComputeSharp etc.)
#
#  The composition is intentionally deterministic: all test suites can rely on
#  stable ports, credentials, and predictable startup ordering enforced via
#  health-checks and depends_on/condition clauses.
# ==========================================================================================
```
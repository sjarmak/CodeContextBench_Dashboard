```go
// Code generated by EchoPulse scaffolder. DO NOT EDIT.
//
// File:        src/module_38.go
// Module:      DriftMonitor
// Description: Real-time feature-distribution drift monitor that observes the
//              platform’s canonical SocialEvents, keeps sliding–window
//              histograms, measures divergence (PSI / KL), and emits structured
//              DriftEvents that can be handled by downstream pipelines
//              (trigger automated retraining, alert dashboards, etc.).

package driftmonitor

import (
	"context"
	"encoding/json"
	"errors"
	"math"
	"sync"
	"time"

	"github.com/google/uuid"
	"github.com/segmentio/kafka-go"
)

// ----------------------------- Public API -----------------------------------

// DriftEvent represents a statistically significant drift between the
// reference window and the current production window.
type DriftEvent struct {
	EventID        string            `json:"event_id"`
	ModelName      string            `json:"model_name"`
	FeatureName    string            `json:"feature_name"`
	Metric         string            `json:"metric"` // "psi" | "kl"
	Value          float64           `json:"value"`
	PValue         float64           `json:"p_value,omitempty"`
	WindowSize     int               `json:"window_size"`
	ReferenceSince time.Time         `json:"reference_since"`
	Timestamp      time.Time         `json:"timestamp"`
	Metadata       map[string]string `json:"metadata,omitempty"`
}

// Observer is the canonical implementation of the Observer pattern used
// across EchoPulse.  Components interested in distribution drift implement the
// interface and register themselves with the monitor.
type Observer interface {
	OnDrift(ctx context.Context, e DriftEvent)
}

// FeedSample is a lightweight DTO for streaming features into the monitor.
type FeedSample struct {
	FeatureName string    // e.g. "sentiment_score"
	Value       float64   // numeric representation; callers pre-encode categorical values
	Timestamp   time.Time // canonicalized event time
}

// Config controls the behaviour of the DriftMonitor.
type Config struct {
	ModelName           string        // logical model/tag under observation
	BinEdges            []float64     // histogram bin split points (sorted asc)
	WindowSize          int           // number of production samples to keep
	ReferenceWindowSize int           // bootstrap size before monitoring starts
	MinPSI              float64       // threshold to fire drift (commonly 0.2 – 0.3)
	MinKL               float64       // alternative KL divergence threshold
	PollInterval        time.Duration // background divergence computation tick
	KafkaTopic          string        // optional – if set, events are published in addition to observers
	KafkaBrokers        []string
}

// NewDefaultConfig returns sane default parameters for scalar features that
// range roughly inside [-1,1] (e.g., sentiment).  Callers are expected to
// override as needed.
func NewDefaultConfig(model, feature string) Config {
	return Config{
		ModelName:           model,
		BinEdges:            []float64{-1, -.5, 0, .5, 1},
		WindowSize:          2000,
		ReferenceWindowSize: 10000,
		MinPSI:              0.25,
		MinKL:               0.15,
		PollInterval:        2 * time.Second,
	}
}

// DriftMonitor ingests individual FeedSamples concurrently, maintains
// reference + sliding windows, computes divergence metrics, and notifies
// observers upon drift.
type DriftMonitor struct {
	cfg        Config
	reference  *histogram
	current    *histogram
	feedCh     chan FeedSample
	cancelFunc context.CancelFunc

	observersMu sync.RWMutex
	observers   map[Observer]struct{}

	kafkaWriter *kafka.Writer
}

// New creates a DriftMonitor with the provided configuration.  Start() must be
// called to begin processing.
func New(cfg Config) (*DriftMonitor, error) {
	if len(cfg.BinEdges) < 2 {
		return nil, errors.New("driftmonitor: at least 2 bin edges required")
	}
	if cfg.WindowSize <= 0 || cfg.ReferenceWindowSize <= 0 {
		return nil, errors.New("driftmonitor: window sizes must be > 0")
	}

	var writer *kafka.Writer
	if len(cfg.KafkaBrokers) > 0 && cfg.KafkaTopic != "" {
		writer = &kafka.Writer{
			Addr:     kafka.TCP(cfg.KafkaBrokers...),
			Topic:    cfg.KafkaTopic,
			Balancer: &kafka.CRC32Balancer{},
		}
	}

	return &DriftMonitor{
		cfg:       cfg,
		reference: newHistogram(cfg.BinEdges, cfg.ReferenceWindowSize),
		current:   newHistogram(cfg.BinEdges, cfg.WindowSize),
		feedCh:    make(chan FeedSample, 16_384),
		observers: make(map[Observer]struct{}),
		kafkaWriter: writer,
	}, nil
}

// Start launches background goroutines to consume FeedSamples and compute drift.
// The caller can cancel the ctx to gracefully stop.
func (m *DriftMonitor) Start(ctx context.Context) {
	ctx, cancel := context.WithCancel(ctx)
	m.cancelFunc = cancel

	go m.ingestLoop(ctx)
	go m.divergenceLoop(ctx)
}

// Close stops all goroutines and flushes resources.
func (m *DriftMonitor) Close() error {
	if m.cancelFunc != nil {
		m.cancelFunc()
	}
	if m.kafkaWriter != nil {
		return m.kafkaWriter.Close()
	}
	return nil
}

// Feed provides non-blocking ingestion API.  When the channel buffer is full,
// the oldest sample is dropped to preserve real-time constraints.
func (m *DriftMonitor) Feed(s FeedSample) {
	select {
	case m.feedCh <- s:
	default:
		// Channel full; drop (back-pressure mechanism)
	}
}

// Register attaches an observer.
func (m *DriftMonitor) Register(o Observer) {
	m.observersMu.Lock()
	defer m.observersMu.Unlock()
	m.observers[o] = struct{}{}
}

// Unregister detaches an observer.
func (m *DriftMonitor) Unregister(o Observer) {
	m.observersMu.Lock()
	defer m.observersMu.Unlock()
	delete(m.observers, o)
}

// ----------------------------- Core Logic -----------------------------------

// ingestLoop continuously reads incoming samples and updates histograms.
func (m *DriftMonitor) ingestLoop(ctx context.Context) {
	for {
		select {
		case <-ctx.Done():
			return
		case s := <-m.feedCh:
			if !m.reference.IsFull() {
				m.reference.Insert(s.Value)
				continue
			}
			m.current.Insert(s.Value)
		}
	}
}

// divergenceLoop ticks at cfg.PollInterval, computes PSI and KL divergence,
// and emits events when drift is detected.
func (m *DriftMonitor) divergenceLoop(ctx context.Context) {
	ticker := time.NewTicker(m.cfg.PollInterval)
	defer ticker.Stop()

	for {
		select {
		case <-ctx.Done():
			return
		case <-ticker.C:
			if !m.reference.IsFull() || !m.current.IsFull() {
				continue
			}
			psi := populationStabilityIndex(m.reference, m.current)
			kl := klDivergence(m.reference, m.current)

			switch {
			case psi >= m.cfg.MinPSI:
				m.emitDrift(ctx, "psi", psi, 0)
			case kl >= m.cfg.MinKL:
				m.emitDrift(ctx, "kl", kl, 0)
			}
		}
	}
}

// emitDrift builds a DriftEvent and notifies all downstream observers / Kafka.
func (m *DriftMonitor) emitDrift(ctx context.Context, metric string, value, p float64) {
	e := DriftEvent{
		EventID:        uuid.NewString(),
		ModelName:      m.cfg.ModelName,
		FeatureName:    "global", // TODO: extend per feature
		Metric:         metric,
		Value:          value,
		PValue:         p,
		WindowSize:     m.cfg.WindowSize,
		ReferenceSince: m.reference.startTime,
		Timestamp:      time.Now().UTC(),
	}

	// Fan-out to registered observers
	m.observersMu.RLock()
	for o := range m.observers {
		go o.OnDrift(ctx, e) // invoke asynchronously
	}
	m.observersMu.RUnlock()

	// Optionally publish to Kafka
	if m.kafkaWriter != nil {
		payload, _ := json.Marshal(e) // safe: never fails for struct
		_ = m.kafkaWriter.WriteMessages(ctx, kafka.Message{
			Key:   []byte(e.EventID),
			Value: payload,
		})
	}
}

// ------------------------ Histogram / Metrics ------------------------------

type histogram struct {
	bins       []int
	edges      []float64
	maxSamples int
	samples    int
	startTime  time.Time
	mu         sync.Mutex
}

func newHistogram(edges []float64, max int) *histogram {
	return &histogram{
		bins:       make([]int, len(edges)+1), // extra bin for right-most edge
		edges:      edges,
		maxSamples: max,
		startTime:  time.Now(),
	}
}

func (h *histogram) Insert(v float64) {
	h.mu.Lock()
	defer h.mu.Unlock()

	// drop old sample if full (simple circular buffer semantics ‑ degrade oldest bin proportionally)
	if h.samples >= h.maxSamples {
		// naive: scale down counts by ratio to make room for 1 sample
		for i := range h.bins {
			if h.bins[i] > 0 {
				h.bins[i] = int(math.Round(float64(h.bins[i]) * float64(h.maxSamples-1) / float64(h.maxSamples)))
			}
		}
		h.samples = h.maxSamples - 1
	}

	idx := h.index(v)
	h.bins[idx]++
	h.samples++
}

func (h *histogram) IsFull() bool {
	h.mu.Lock()
	defer h.mu.Unlock()
	return h.samples >= h.maxSamples
}

func (h *histogram) index(v float64) int {
	for i, edge := range h.edges {
		if v <= edge {
			return i
		}
	}
	return len(h.edges) // right-most bin
}

// toProbs copies and converts counts to probability distribution.
func (h *histogram) toProbs() []float64 {
	h.mu.Lock()
	defer h.mu.Unlock()

	total := float64(h.samples)
	p := make([]float64, len(h.bins))
	if total == 0 {
		return p
	}
	for i, c := range h.bins {
		p[i] = float64(c) / total
	}
	return p
}

// populationStabilityIndex calculates PSI between reference and production
// distributions.  A typical rule: PSI > 0.25 signals significant drift.
func populationStabilityIndex(ref, cur *histogram) float64 {
	r := ref.toProbs()
	p := cur.toProbs()

	const epsilon = 1e-12
	psi := 0.0
	for i := range r {
		expected := r[i] + epsilon
		actual := p[i] + epsilon
		psi += (actual - expected) * math.Log(actual/expected)
	}
	return psi
}

// klDivergence calculates Kullback-Leibler divergence.
func klDivergence(ref, cur *histogram) float64 {
	r := ref.toProbs()
	p := cur.toProbs()

	const epsilon = 1e-12
	kl := 0.0
	for i := range r {
		q := r[i] + epsilon
		d := p[i] + epsilon
		kl += d * math.Log(d/q)
	}
	return kl
}
```
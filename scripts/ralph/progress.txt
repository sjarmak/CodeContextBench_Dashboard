# Ralph Progress Log
Started: Mon Jan 27 13:12:00 EST 2026

## Codebase Patterns
- Dashboard framework: Streamlit with Plotly charts, Pandas for data processing
- Dashboard entry point: dashboard/app.py with views in dashboard/views/
- Data ingestion: src/ingest/ (transcript_parser.py, harbor_parser.py, database.py)
- Analysis modules: src/analysis/ (8 analyzers: statistical, comparator, cost, failure, time_series, ir, llm_judge, recommendation)
- Benchmark management: src/benchmark/ (database.py, llm_judge.py, trace_parser.py)
- Config files: configs/ directory with YAML and JSON formats
- claude-code.txt is JSONL format (one JSON object per line), NOT plain text
- Token usage embedded in assistant message usage field (input_tokens, output_tokens, cache_creation_input_tokens, cache_read_input_tokens)
- parent_tool_use_id links sub-agent tool calls to parent for hierarchical traces
- Experiment runs have manifest.json (metadata), index.json (task-to-run mapping), runs/ and pairs/ subdirs
- Task config.json contains agent info (model, import_path) and task info (path, git_url, source)
- Result.json contains verifier_result.rewards, agent_result (tokens, cost), timing data
- LoCoBench task IDs follow: {language}_{domain}_{complexity}_{num}_{task_category}_{difficulty}_{variant}
- SWE-Bench Pro task IDs follow: instance_{org}__{repo}__{hash}
- Runs directory path: ~/evals/custom_agents/agents/claudecode/runs/
---
